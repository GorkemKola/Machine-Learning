{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART I: Theory Questions\n",
    "\n",
    "1) Consider the convolutional neural network defined by the layer|s in the left column below. Fill in the shape of the output volume and the number of parameters at each layer. You can write the shapes in the numpy format (e.g. (64,64,3))\n",
    "\n",
    "| Layer | Output Volume Shape | Number of parameters |\n",
    "|---|---|---|\n",
    "| Input | (127x127x4) | 0 |\n",
    "| CONV3-10 | (125x125x10) | 3x3x10x4+10=370 |\n",
    "| POOL-3 | (41x41x10) | 0 |\n",
    "| CONV3-10 | (39x39x10) | 3x3x10x10+10=910 |\n",
    "| POOL-2 | (19x19x10) | 0 |\n",
    "| FC-20 | (20) | 20x19x19x10+20=72220 |\n",
    "| FC-10 | (10) | 20x10+10=210 |\n",
    "\n",
    "\n",
    "2) Consider the simple neuron structure below:\n",
    "\n",
    "![Question 2 Image](q2.png)\n",
    "\n",
    "\n",
    "Assume that the weights for the neuron are w1 = 3, w2 = -5, and w3 = 2 with activation function below:\n",
    "$$v(x) =\n",
    "\\begin{cases}\n",
    "1, & \\text{if } x > 0 \\\\\n",
    "0, & \\text{otherwise}\n",
    "\\end{cases}$$\n",
    "\n",
    "find the output y values for the input patterns below:\n",
    "\n",
    "| INPUT | I1 | I2 | I3 | I4 |\n",
    "|---|---|---|---|---|\n",
    "| x1 | 1 | 0 | 1 | 1 |\n",
    "| x2 | 0 | 1 | 0 | 1 |\n",
    "| x3 | 0 | 1 | 1 | 1 |\n",
    "\n",
    "| Output | I1 | I2 | I3 | I4 |\n",
    "|---|---|---|---|---|\n",
    "| Output | v(3x1-5x0+2x0)=v(3)=1 | v(3x0-5x1+2x1)=v(-3)=0 | v(3x1-5x0+2x1)=v(5)=1 | v(3x1-5x1+2x1)=v(0)=0|\n",
    "\n",
    "3) Consider the multi-layer neural network below:\n",
    "\n",
    "![Question 3 Image](q3.png)\n",
    "\n",
    "- Find how many weight variables the network has in total (Ignore bias values). Show your calculations.\n",
    "\n",
    "    - Input-1st Hidden Layer: 3*5 = 15\n",
    "    - 1st Hidden Layer - 2nd Hidden Layer: 5*3 = 15\n",
    "    - 2nd Hidden Layer - Output Layer: 3*2 = 6\n",
    "\n",
    "    - In total 36\n",
    "\n",
    "- Find how many weight variables the network has in total if the network is considered as fully connected (Ignore bias values). Show your calculations \n",
    "    - The same as the first part, as Neural Network is Fully Connected.\n",
    "    \n",
    "    - Input-1st Hidden Layer: 3*5 = 15\n",
    "    - 1st Hidden Layer - 2nd Hidden Layer: 5*3 = 15\n",
    "    - 2nd Hidden Layer - Output Layer: 3*2 = 6\n",
    "\n",
    "    - In total 36\n",
    "\n",
    "- State the dependency information for nodes given number values, which are about which node takes information from which previous node. State also these dependencies for both forward and back-propagation streams.\n",
    "\n",
    "Lets assume;\n",
    "$x_{ij}$ represents a node\n",
    "\n",
    "i: represents layer id, from 0 to number of layers\n",
    "\n",
    "j: represents node id.\n",
    "\n",
    "##### Forward Propagation:\n",
    "As it is a fully connected layer, we know that every node in $x_{i+1}$, is dependent to previous layer's ($x_{i}$) nodes and the weights $w_{i/i+1}$.\n",
    "\n",
    "we can formulate it as this:\n",
    "\n",
    "#### $n_{i+1}$ = $w_{i/i+1}.T$ @ $n_{i}$\n",
    "\n",
    "T: takes the transpose of matrix given,\n",
    "@: Matrix Multiplication.\n",
    "\n",
    "As the formula above, every node values are dependent to previous node values.\n",
    "\n",
    "##### Backward Propagation:\n",
    "On backward propagation we calculate loss then, apply derivatives to each layer, from output layer to input layer, give derivative information using Chain Rule.\n",
    "\n",
    "The formula looks like this:\n",
    "#### $ \\frac{d_{L}}{d_{w_{i/i+1}}} = \\frac{d_{L}}{d_{w_{i-1/i}}} . \\frac{d_{w_{i/i+1}}}{d_{w_{i-1/i}}} $\n",
    "\n",
    "As every weight is dependent to loss information coming from the next layer, and nodes are dependent to weight values, every node is dependent to next nodes also in backward pass context.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2\n",
    "\n",
    "## Multi Layer Neural Network\n",
    "\n",
    "- In this part, we are expected to classify mel spectogram image dataset with respect to age information, but as data have gender and accent information also, let's classify as multilabel classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Importing important libraries\n",
    "_____________________________\n",
    "numpy:matrix operations\n",
    "pillow:to read images\n",
    "pandas: csv and excel operations\n",
    "os: folder operations\n",
    "sklearn: to One hot encode and calculate accuracy\n",
    "tqdm: to see progress bar.\n",
    "logging: to log the output values\n",
    "'''\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename='logfile.txt', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading CSV files\n",
    "train_df = pd.read_csv('dataset_a3/voice_dataset/train_data.csv')\n",
    "test_df = pd.read_csv('dataset_a3/voice_dataset/test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>accent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sample-084720.png</td>\n",
       "      <td>i had seen all that it would presently bring me</td>\n",
       "      <td>twenties</td>\n",
       "      <td>other</td>\n",
       "      <td>england</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sample-169346.png</td>\n",
       "      <td>a friend had told the boy about the shop and h...</td>\n",
       "      <td>twenties</td>\n",
       "      <td>male</td>\n",
       "      <td>england</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sample-027740.png</td>\n",
       "      <td>the boy said nothing</td>\n",
       "      <td>twenties</td>\n",
       "      <td>male</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sample-035454.png</td>\n",
       "      <td>what is the matter</td>\n",
       "      <td>twenties</td>\n",
       "      <td>male</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sample-134062.png</td>\n",
       "      <td>no baselines or comparison to state of the art...</td>\n",
       "      <td>twenties</td>\n",
       "      <td>female</td>\n",
       "      <td>australia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            filename                                               text  \\\n",
       "0  sample-084720.png    i had seen all that it would presently bring me   \n",
       "1  sample-169346.png  a friend had told the boy about the shop and h...   \n",
       "2  sample-027740.png                               the boy said nothing   \n",
       "3  sample-035454.png                                 what is the matter   \n",
       "4  sample-134062.png  no baselines or comparison to state of the art...   \n",
       "\n",
       "        age  gender     accent  \n",
       "0  twenties   other    england  \n",
       "1  twenties    male    england  \n",
       "2  twenties    male     indian  \n",
       "3  twenties    male         us  \n",
       "4  twenties  female  australia  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>accent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sample-008291.png</td>\n",
       "      <td>watching the parody was great entertainment</td>\n",
       "      <td>twenties</td>\n",
       "      <td>male</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sample-099767.png</td>\n",
       "      <td>what'll i tell him</td>\n",
       "      <td>twenties</td>\n",
       "      <td>male</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sample-149649.png</td>\n",
       "      <td>it was a strange furnace fueled by firewood wi...</td>\n",
       "      <td>twenties</td>\n",
       "      <td>female</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sample-183749.png</td>\n",
       "      <td>and she already has her treasure it's you</td>\n",
       "      <td>twenties</td>\n",
       "      <td>other</td>\n",
       "      <td>ireland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sample-192527.png</td>\n",
       "      <td>not everyone can see his dreams come true in t...</td>\n",
       "      <td>twenties</td>\n",
       "      <td>male</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            filename                                               text  \\\n",
       "0  sample-008291.png        watching the parody was great entertainment   \n",
       "1  sample-099767.png                                 what'll i tell him   \n",
       "2  sample-149649.png  it was a strange furnace fueled by firewood wi...   \n",
       "3  sample-183749.png          and she already has her treasure it's you   \n",
       "4  sample-192527.png  not everyone can see his dreams come true in t...   \n",
       "\n",
       "        age  gender   accent  \n",
       "0  twenties    male   indian  \n",
       "1  twenties    male       us  \n",
       "2  twenties  female       us  \n",
       "3  twenties   other  ireland  \n",
       "4  twenties    male   indian  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images(paths, ratio):\n",
    "    image = Image.open(paths[0])\n",
    "    images = np.zeros((len(paths), image.size[1] // ratio, image.size[0] // ratio, 4))\n",
    "    for i, path in enumerate(paths):\n",
    "        image = Image.open(path)\n",
    "        image = image.resize((image.size[0] // ratio, image.size[1] // ratio))\n",
    "        image = np.array(image) / 255\n",
    "        images[i] = image\n",
    "    return images\n",
    "\n",
    "def encode(train, test):\n",
    "    # Reshape to a 2D array (column vector)\n",
    "    train = np.array(train).reshape(-1, 1)\n",
    "    test = np.array(test).reshape(-1, 1)\n",
    "\n",
    "    # Initialize the OneHotEncoder\n",
    "    encoder = OneHotEncoder()\n",
    "\n",
    "    # Fit and transform the training data\n",
    "    train_encoded = encoder.fit_transform(train).toarray()\n",
    "\n",
    "    # Transform the test data\n",
    "    test_encoded = encoder.transform(test).toarray()\n",
    "\n",
    "    return encoder, train_encoded, test_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths = train_df['filename']\n",
    "test_paths = test_df['filename']\n",
    "age_encoder, train_age, test_age = encode(train_df['age'], test_df['age'])\n",
    "gender_encoder, train_gender, test_gender = encode(train_df['gender'], test_df['gender'])\n",
    "accent_encoder, train_accent, test_accent = encode(train_df['accent'], test_df['accent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    '''\n",
    "        Dataset class to replicate Pytorch Datasets\n",
    "        ____________________________________________\n",
    "\n",
    "        Parameters\n",
    "        ____________\n",
    "\n",
    "        image_dir : str\n",
    "            the directory contains images\n",
    "\n",
    "        image_paths : list[str]\n",
    "            the relative paths to image_dir\n",
    "\n",
    "        age : np.array\n",
    "            Age array\n",
    "\n",
    "        gender : np.array\n",
    "            Gender array\n",
    "\n",
    "        accent : np.array\n",
    "            Accent array\n",
    "\n",
    "    '''\n",
    "    def __init__(self, image_dir: str, \n",
    "                 image_paths: list[str], \n",
    "                 age: np.array, \n",
    "                 gender: np.array, \n",
    "                 accent: np.array):\n",
    "        self.image_dir = image_dir\n",
    "        self.image_paths = list(map(lambda p: os.path.join(image_dir, p), image_paths))\n",
    "        self.age = age\n",
    "        self.gender = gender\n",
    "        self.accent = accent\n",
    "\n",
    "    def __getitem__(self, indices):\n",
    "        return read_images(self.image_paths[indices], 10), \\\n",
    "                self.age[indices], \\\n",
    "                self.gender[indices], \\\n",
    "                self.accent[indices]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def shuffle(self, random_seed=None):\n",
    "        if random_seed is not None:\n",
    "            np.random.seed(random_seed)\n",
    "        indices = np.arange(len(self.image_paths))\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "        self.image_paths = [self.image_paths[i] for i in indices]\n",
    "        self.age = self.age[indices]\n",
    "        self.gender = self.gender[indices]\n",
    "        self.accent = self.accent[indices]\n",
    "    \n",
    "    def split_dataset(self, train_ratio=0.8, random_seed=None):\n",
    "        if random_seed is not None:\n",
    "            np.random.seed(random_seed)\n",
    "\n",
    "        num_samples = len(self.image_paths)\n",
    "        indices = np.arange(num_samples)\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "        train_size = int(train_ratio * num_samples)\n",
    "\n",
    "        train_indices = indices[:train_size]\n",
    "        val_indices = indices[train_size:]\n",
    "\n",
    "        train_dataset = Dataset(\n",
    "            image_dir='',\n",
    "            image_paths=[self.image_paths[i] for i in train_indices],\n",
    "            age=self.age[train_indices],\n",
    "            gender=self.gender[train_indices],\n",
    "            accent=self.accent[train_indices]\n",
    "        )\n",
    "\n",
    "        val_dataset = Dataset(\n",
    "            image_dir='',\n",
    "            image_paths=[self.image_paths[i] for i in val_indices],\n",
    "            age=self.age[val_indices],\n",
    "            gender=self.gender[val_indices],\n",
    "            accent=self.accent[val_indices]\n",
    "        )\n",
    "\n",
    "        return train_dataset, val_dataset\n",
    "    \n",
    "class DataLoader():\n",
    "    '''\n",
    "        The dataLoader class to replicate Pytorch Dataloaders\n",
    "        _____________________________________________________\n",
    "\n",
    "        Parameters\n",
    "        __________\n",
    "        \n",
    "        batch_size : int\n",
    "            Batch Size\n",
    "\n",
    "        dataset : Dataset\n",
    "            Dataset\n",
    "    '''\n",
    "    def __init__(self, batch_size: int, dataset: Dataset) -> None:\n",
    "        self.batch_size = batch_size\n",
    "        self.dataset = dataset\n",
    "        self.idx = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        if self.idx >= len(self.dataset):\n",
    "            self.idx = 0\n",
    "            raise StopIteration\n",
    "\n",
    "        batch = self.dataset[self.idx:self.idx+self.batch_size]\n",
    "\n",
    "        self.idx += self.batch_size\n",
    "\n",
    "        return batch\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset) // self.batch_size\n",
    "    \n",
    "    def __getitem__(self, indices):\n",
    "        return self.dataset[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(image_dir='dataset_a3/voice_dataset/train/', \n",
    "                        image_paths=train_paths, \n",
    "                        age=train_age,\n",
    "                        gender=train_gender,\n",
    "                        accent=train_accent)\n",
    "\n",
    "test_dataset = Dataset(image_dir='dataset_a3/voice_dataset/test/', \n",
    "                        image_paths=test_paths, \n",
    "                        age=test_age,\n",
    "                        gender=test_gender,\n",
    "                        accent=test_accent)\n",
    "\n",
    "train_dataset, val_dataset = train_dataset.split_dataset(0.8, 42)\n",
    "train_dataset.shuffle(42)\n",
    "val_dataset.shuffle(42)\n",
    "test_dataset.shuffle(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import issparse\n",
    "def softmax(x):\n",
    "    '''\n",
    "        Softmax activation function\n",
    "        ___________________________\n",
    "        Parameters\n",
    "        __________\n",
    "        x : np.array\n",
    "            mini batch array will be activated.\n",
    "\n",
    "        Formula\n",
    "        _________\n",
    "        x = e**(x) / sum(e**(x))\n",
    "    '''\n",
    "    e_x = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
    "    return e_x / np.sum(e_x, axis=-1, keepdims=True)\n",
    "\n",
    "def softmax_derivative(x):\n",
    "    '''\n",
    "        Softmax activation function derivative\n",
    "        ___________________________\n",
    "        Parameters\n",
    "        __________\n",
    "        x : np.array\n",
    "            mini batch array will be derived.\n",
    "    '''\n",
    "    s = softmax(x)\n",
    "    return s * (1 - s)\n",
    "\n",
    "def negative_log_likelihood_loss(y_true, y_pred):\n",
    "    '''\n",
    "        Negative Log Likelihood (NLL) Loss calculation Function\n",
    "        _______________________________________________________\n",
    "\n",
    "        Parameters\n",
    "        _______________\n",
    "        y_true : np.array\n",
    "            True Labels\n",
    "\n",
    "        y_pred : np.array\n",
    "            Predicted Labels\n",
    "\n",
    "        Formula\n",
    "        ____________\n",
    "        loss = - Sigma(n: 1 to N), Sigma(k: 1 to K) y_true[k][n] * log(y_pred[k][n])\n",
    "    '''\n",
    "\n",
    "    # Epsilon value to avoid log(0)\n",
    "    epsilon = 1e-10\n",
    "\n",
    "    # Clip values utilizing epsilon\n",
    "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
    "    \n",
    "    if issparse(y_true):\n",
    "        y_true = y_true.toarray()\n",
    "\n",
    "    loss = -np.sum(np.multiply(y_true, np.log(y_pred + epsilon))) / len(y_true)\n",
    "    return loss\n",
    "\n",
    "def nll_loss_derivative(y_true, y_pred, epsilon=1e-10):\n",
    "    '''\n",
    "        Negative Log Likelihood (NLL) Loss derivative calculation Function\n",
    "\n",
    "        Parameters\n",
    "        _______________\n",
    "        y_true : np.array\n",
    "            True Labels\n",
    "\n",
    "        y_pred : np.array\n",
    "            Predicted Labels\n",
    "\n",
    "        epsilon : float, optional\n",
    "            A small value to avoid division by zero, by default 1e-10\n",
    "    '''\n",
    "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
    "    return -(y_true / y_pred)\n",
    "\n",
    "def relu(x):\n",
    "    '''\n",
    "        ReLU activation function, it is easy as below 0 values will be mapped to 0 and upper 0 values will be keeped the same.\n",
    "        ____________\n",
    "\n",
    "        Parameters\n",
    "        __________\n",
    "        x : np.array\n",
    "            mini batch will be activated\n",
    "    '''\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "\n",
    "def relu_derivative(x):\n",
    "    '''\n",
    "        Derivative of ReLU\n",
    "        __________________\n",
    "        it is simple as relu contains x or 0\n",
    "        derivative of x is 1\n",
    "        derivative of 0 is 0\n",
    "\n",
    "        Parameters\n",
    "        __________\n",
    "        x : np.array\n",
    "            mini batch, derivative will be taken from\n",
    "    '''\n",
    "    return np.where(x > 0, 1, 0)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    '''\n",
    "    Derivative of Sigmoid\n",
    "    _____________________\n",
    "\n",
    "    It is similar to softmax derivative.\n",
    "\n",
    "    Parameters\n",
    "    __________\n",
    "    x : np.array\n",
    "        mini batch, derivative will be taken from\n",
    "    '''\n",
    "    sig = sigmoid(x)\n",
    "    return sig * (1 - sig)\n",
    "\n",
    "def hardmax(x):\n",
    "  \"\"\"Hardmax activation for prediction.\"\"\"\n",
    "  return np.argmax(x, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    '''\n",
    "    The Base Layer\n",
    "    '''\n",
    "    def __init__(self) -> None:\n",
    "        self.input = None\n",
    "        self.output = None\n",
    "\n",
    "    def forward(self, input):\n",
    "        # TODO: Return output\n",
    "        pass\n",
    "\n",
    "    def backward(self, output_gradient, learning_rate):\n",
    "        # TODO: Update parameters and return input gradient.\n",
    "        pass\n",
    "\n",
    "\n",
    "class FullyConnectedLayer(Layer):\n",
    "    '''\n",
    "    Fully Connected (Dense) Layer\n",
    "    \n",
    "    Parameters:\n",
    "        input_size: Input size of Layer\n",
    "        output_Size: Output Size of Layer\n",
    "\n",
    "    Arguments:\n",
    "        weights: Weight Array\n",
    "        bias: Bias Array\n",
    "        Input: Stores input came to backpropagate.\n",
    "    '''\n",
    "    def __init__(self, input_size, output_size) -> None:\n",
    "        super().__init__()\n",
    "        self.weights = np.random.randn(input_size, output_size) * np.sqrt(2 / (input_size + output_size))\n",
    "        self.bias = np.zeros((1, output_size))\n",
    "        self.input = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.input = x\n",
    "        return x @ self.weights + self.bias\n",
    "    \n",
    "    def backward(self, output_error, learning_rate):\n",
    "        weights_delta = self.input.T @ output_error\n",
    "        bias_delta = np.sum(output_error, axis=0)\n",
    "\n",
    "        # Save the updated error in a temporary variable\n",
    "        updated_error = output_error @ self.weights.T\n",
    "\n",
    "        # Update weights\n",
    "        self.weights -= learning_rate * weights_delta\n",
    "\n",
    "        # Update bias\n",
    "        self.bias -= learning_rate * bias_delta.reshape(1, -1)\n",
    "\n",
    "        return updated_error\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return self.forward(x)\n",
    "    \n",
    "class ActivationLayer(Layer):\n",
    "    '''\n",
    "    Activation Layer\n",
    "\n",
    "    Parameters:\n",
    "        activation_function: ReLU or Sigmoid\n",
    "        activation_deriavative: Derivative Function of Activation Funciton\n",
    "    '''\n",
    "    def __init__(self, activation_function, activation_derivative) -> None:\n",
    "        super().__init__()\n",
    "        self.activation_function = activation_function\n",
    "        self.activation_derivative = activation_derivative\n",
    "        self.input = None\n",
    "    def forward(self, x):\n",
    "        self.input = x\n",
    "        return self.activation_function(x)\n",
    "    \n",
    "    def backward(self, output_error):\n",
    "        return np.multiply(output_error, self.activation_derivative(self.input))\n",
    "            \n",
    "    def __call__(self, x):\n",
    "        return self.forward(x)\n",
    "    \n",
    "    \n",
    "class NeuralNetwork():\n",
    "    '''\n",
    "    Multi Layer Perceptron\n",
    "\n",
    "    Parameters:\n",
    "        input_size: input size of data\n",
    "        hidden_size: hidden layer size\n",
    "        age_size: Age output size\n",
    "        gender_size: Gender output size\n",
    "        accent_size: Accent output size\n",
    "        activation_function: ReLU or Sigmoid\n",
    "        activation_derivative: Derivative of Activation Function\n",
    "        hidden_layer_size: int\n",
    "    '''\n",
    "    def __init__(self, \n",
    "                 input_size: int, \n",
    "                 hidden_size: int, \n",
    "                 age_size: int, \n",
    "                 gender_size: int, \n",
    "                 accent_size: int, \n",
    "                 activation_function, \n",
    "                 activation_derivative, \n",
    "                 hidden_layer_size: int) -> None:\n",
    "        \n",
    "        self.hidden_layers = []\n",
    "        for _ in range(hidden_layer_size):\n",
    "            self.hidden_layers.append(FullyConnectedLayer(input_size, hidden_size))\n",
    "            self.hidden_layers.append(ActivationLayer(activation_function, activation_derivative))\n",
    "            input_size = hidden_size\n",
    "            hidden_size //= 2\n",
    "\n",
    "        self.age_fc = FullyConnectedLayer(input_size, age_size)\n",
    "        self.age_af = ActivationLayer(softmax, softmax_derivative)\n",
    "\n",
    "        self.gender_fc = FullyConnectedLayer(input_size, gender_size)\n",
    "        self.gender_af = ActivationLayer(softmax, softmax_derivative)\n",
    "\n",
    "        self.accent_fc = FullyConnectedLayer(input_size, accent_size)\n",
    "        self.accent_af = ActivationLayer(softmax, softmax_derivative)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.hidden_layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        age = self.age_fc(x)\n",
    "        age = self.age_af(age)\n",
    "\n",
    "        gender = self.gender_fc(x)\n",
    "        gender = self.gender_af(gender)\n",
    "\n",
    "        accent = self.accent_fc(x)\n",
    "        accent = self.accent_af(accent)\n",
    "\n",
    "        return age, gender, accent\n",
    "    \n",
    "    def backward(self, y_true, y_pred, learning_rate):\n",
    "        age_true, gender_true, accent_true = y_true\n",
    "        age_pred, gender_pred, accent_pred = y_pred\n",
    "\n",
    "        age_error = nll_loss_derivative(age_true, age_pred)\n",
    "        age_error = self.age_af.backward(age_error)\n",
    "        age_error = self.age_fc.backward(age_error, learning_rate)\n",
    "\n",
    "        gender_error = nll_loss_derivative(gender_true, gender_pred)\n",
    "        gender_error = self.gender_af.backward(gender_error)\n",
    "        gender_error = self.gender_fc.backward(gender_error, learning_rate)\n",
    "\n",
    "        accent_error = nll_loss_derivative(accent_true, accent_pred)\n",
    "        accent_error = self.accent_af.backward(accent_error)\n",
    "        accent_error = self.accent_fc.backward(accent_error, learning_rate)\n",
    "\n",
    "        for layer in reversed(self.hidden_layers):\n",
    "            if isinstance(layer, FullyConnectedLayer):\n",
    "                age_error = layer.backward(age_error, learning_rate)\n",
    "                gender_error = layer.backward(gender_error, learning_rate)\n",
    "                accent_error = layer.backward(accent_error, learning_rate)\n",
    "            elif isinstance(layer, ActivationLayer):\n",
    "                age_error = layer.backward(age_error)\n",
    "                gender_error = layer.backward(gender_error)\n",
    "                accent_error = layer.backward(accent_error)\n",
    "\n",
    "        return age_error + gender_error + accent_error\n",
    "\n",
    "\n",
    "    def train(self, train_loader, epochs, learning_rate, val_loader=None):\n",
    "        for epoch in range(epochs):\n",
    "            self._run_epoch(train_loader, epochs, learning_rate, epoch, \"Train\")\n",
    "\n",
    "            if val_loader is not None:\n",
    "                self._run_epoch(val_loader, epochs, learning_rate, epoch, \"Validation\")\n",
    "\n",
    "\n",
    "    def _run_epoch(self, data_loader, epochs, learning_rate, epoch, mode=\"Train\"):\n",
    "        prefix = \"Epoch\" if mode == \"Train\" else \"Val\"\n",
    "        epoch_loss = 0\n",
    "        epoch_age_acc, epoch_gender_acc, epoch_accent_acc = 0, 0, 0\n",
    "\n",
    "        # Use tqdm to create a progress bar\n",
    "        for x, age_true, gender_true, accent_true in tqdm(data_loader, desc=f\"{prefix} {epoch+1}/{epochs}\"):\n",
    "            x = x.reshape(x.shape[0], -1)\n",
    "            age_pred, gender_pred, accent_pred = self.forward(x)\n",
    "\n",
    "            age_accuracy = accuracy_score(hardmax(age_true), hardmax(age_pred))\n",
    "            gender_accuracy = accuracy_score(hardmax(gender_true), hardmax(gender_pred))\n",
    "            accent_accuracy = accuracy_score(hardmax(accent_true), hardmax(accent_pred))\n",
    "\n",
    "            age_loss = negative_log_likelihood_loss(age_true, age_pred)\n",
    "            gender_loss = negative_log_likelihood_loss(gender_true, gender_pred)\n",
    "            accent_loss = negative_log_likelihood_loss(accent_true, accent_pred)\n",
    "\n",
    "            loss = age_loss + gender_loss + accent_loss\n",
    "            epoch_loss += loss\n",
    "\n",
    "            epoch_age_acc += age_accuracy\n",
    "            epoch_gender_acc += gender_accuracy\n",
    "            epoch_accent_acc += accent_accuracy\n",
    "\n",
    "            if mode == \"Train\":\n",
    "                # Backward propagation only in training mode\n",
    "                self.backward(y_true=(age_true, gender_true, accent_true),\n",
    "                            y_pred=(age_pred, gender_pred, accent_pred),\n",
    "                            learning_rate=learning_rate)\n",
    "\n",
    "        epoch_loss /= len(data_loader)\n",
    "        epoch_age_acc /= len(data_loader)\n",
    "        epoch_gender_acc /= len(data_loader)\n",
    "        epoch_accent_acc /= len(data_loader)\n",
    "\n",
    "        logging.info(f'\\n{prefix} Loss: {epoch_loss:.4f}, Age Accuracy: {epoch_age_acc:.4f}, Gender Accuracy: {epoch_gender_acc:.4f}, Accent Accuracy: {epoch_accent_acc:.4f}')\n",
    "        logging.info('__________________________________________________________________________________')\n",
    "\n",
    "\n",
    "    def test(self, test_loader):\n",
    "        epoch_age_acc, epoch_gender_acc, epoch_accent_acc = 0, 0, 0\n",
    "\n",
    "        # Use tqdm to create a progress bar\n",
    "        for (x, age_true, gender_true, accent_true) in tqdm(test_loader, desc=\"Testing\"):\n",
    "            x = x.reshape(x.shape[0], -1)\n",
    "            age_pred, gender_pred, accent_pred = self.forward(x)\n",
    "\n",
    "            age_accuracy = accuracy_score(hardmax(age_true), hardmax(age_pred))\n",
    "            gender_accuracy = accuracy_score(hardmax(gender_true), hardmax(gender_pred))\n",
    "            accent_accuracy = accuracy_score(hardmax(accent_true), hardmax(accent_pred))\n",
    "\n",
    "            epoch_age_acc += age_accuracy\n",
    "            epoch_gender_acc += gender_accuracy\n",
    "            epoch_accent_acc += accent_accuracy\n",
    "\n",
    "        epoch_age_acc /= len(test_loader)\n",
    "        epoch_gender_acc /= len(test_loader)\n",
    "        epoch_accent_acc /= len(test_loader)\n",
    "\n",
    "        logging.info(f'\\Test Age Accuracy: {epoch_age_acc:.4f}, Gender Accuracy: {epoch_gender_acc:.4f}, Accent Accuracy: {epoch_accent_acc:.4f}')\n",
    "        logging.info('__________________________________________________________________________________')\n",
    "\n",
    "        return epoch_age_acc, epoch_gender_acc, epoch_accent_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(model_name, hidden_layer_size, batch_size, activation_function, learning_rate):\n",
    "    '''\n",
    "    Train and Evaluate function for MLP model.\n",
    "    Parameters:\n",
    "        model_name: Model's name will to save results\n",
    "        hidden_layer_Size: Size of Hidden Layers.\n",
    "        batch_size: Batch Size\n",
    "        activation_function, ReLU or Sigmoid activation Function\n",
    "        learning_rate: Learning rate alpha to write learning rates.\n",
    "\n",
    "    Returns:\n",
    "        Dictionary that contains information about model, training and accuracies. \n",
    "    '''\n",
    "    activation_functions = {'relu':relu, 'sigmoid':sigmoid}\n",
    "    activation_derivatives = {'relu':relu_derivative, 'sigmoid':sigmoid_derivative}\n",
    "\n",
    "    model = NeuralNetwork(input_size=30*77*4,\n",
    "                          hidden_size=64,\n",
    "                          age_size=len(train_df['age'].unique()),\n",
    "                          gender_size=len(train_df['gender'].unique()),\n",
    "                          accent_size=len(train_df['accent'].unique()),\n",
    "                          activation_function=activation_functions[activation_function],\n",
    "                          activation_derivative=activation_derivatives[activation_function],\n",
    "                          hidden_layer_size=hidden_layer_size)\n",
    "\n",
    "    train_loader = DataLoader(batch_size, train_dataset)\n",
    "    val_loader = DataLoader(batch_size, val_dataset)\n",
    "\n",
    "    model.train(train_loader=train_loader, \n",
    "                epochs=10, \n",
    "                learning_rate=learning_rate,\n",
    "                val_loader=val_loader)\n",
    "\n",
    "    test_loader = DataLoader(batch_size, test_dataset)  # Provide your evaluation data\n",
    "    age_accuracy, gender_accuracy, accent_accuracy = model.test(test_loader)\n",
    "\n",
    "    return {\n",
    "        'Model': model_name,\n",
    "        'Number of Hidden Layers': hidden_layer_size,\n",
    "        'Batch Size': batch_size,\n",
    "        'Activation Function': activation_function,\n",
    "        'Learning Rate': learning_rate,\n",
    "        'Age Accuracy': age_accuracy,\n",
    "        'Gender Accuracy': gender_accuracy,\n",
    "        'Accent Accuracy': accent_accuracy\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configurations = [\n",
    "    ('MLP', 0, 16, 'relu', 1e-5),\n",
    "    ('MLP', 0, 64, 'relu', 1e-5),\n",
    "    ('MLP', 0, 16, 'sigmoid', 1e-5),\n",
    "    ('MLP', 0, 64, 'sigmoid', 1e-5),\n",
    "    ('MLP', 0, 16, 'relu', 1e-4),\n",
    "    ('MLP', 0, 64, 'relu',  1e-4),\n",
    "    ('MLP', 0, 16, 'sigmoid', 1e-4),\n",
    "    ('MLP', 0, 64, 'sigmoid', 1e-4),\n",
    "    \n",
    "    ('MLP', 1, 16, 'relu', 1e-5),\n",
    "    ('MLP', 1, 64, 'relu', 1e-5),\n",
    "    ('MLP', 1, 16, 'sigmoid', 1e-5),\n",
    "    ('MLP', 1, 64, 'sigmoid', 1e-5),\n",
    "    ('MLP', 1, 16, 'relu', 1e-4),\n",
    "    ('MLP', 1, 64, 'relu', 1e-4),\n",
    "    ('MLP', 1, 16, 'sigmoid', 1e-4),\n",
    "    ('MLP', 1, 64, 'sigmoid', 1e-4),\n",
    "\n",
    "    ('MLP', 2, 16, 'relu', 1e-5),\n",
    "    ('MLP', 2, 64, 'relu', 1e-5),\n",
    "    ('MLP', 2, 16, 'sigmoid', 1e-5),\n",
    "    ('MLP', 2, 64, 'sigmoid', 1e-5),\n",
    "    ('MLP', 2, 16, 'relu', 1e-4),\n",
    "    ('MLP', 2, 64, 'relu', 1e-4),\n",
    "    ('MLP', 2, 16, 'sigmoid', 1e-4),\n",
    "    ('MLP', 2, 64, 'sigmoid', 1e-4),\n",
    "]\n",
    "model_configurations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(columns=['Model', 'Number of Hidden Layers', 'Batch Size', 'Activation Function', 'Learning Rate', 'Age Accuracy', 'Gender Accuracy', 'Accent Accuracy'])\n",
    "results_df = pd.read_excel('model_results.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" for model_name, hidden_layer_size, batch_size, activation_function, learning_rate in model_configurations:\\n    logging.info('////////////////////////////////////')\\n    results = train_and_evaluate_model(model_name, hidden_layer_size, batch_size, activation_function, learning_rate)\\n    results_df = pd.concat([results_df, pd.DataFrame([results], columns=results_df.columns)], ignore_index=True) \""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" for model_name, hidden_layer_size, batch_size, activation_function, learning_rate in model_configurations:\n",
    "    logging.info('////////////////////////////////////')\n",
    "    results = train_and_evaluate_model(model_name, hidden_layer_size, batch_size, activation_function, learning_rate)\n",
    "    results_df = pd.concat([results_df, pd.DataFrame([results], columns=results_df.columns)], ignore_index=True) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Number of Hidden Layers</th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Activation Function</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Age Accuracy</th>\n",
       "      <th>Gender Accuracy</th>\n",
       "      <th>Accent Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.227917</td>\n",
       "      <td>0.709583</td>\n",
       "      <td>0.448333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.225084</td>\n",
       "      <td>0.727196</td>\n",
       "      <td>0.460726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.708750</td>\n",
       "      <td>0.448333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.240709</td>\n",
       "      <td>0.724662</td>\n",
       "      <td>0.460726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.236667</td>\n",
       "      <td>0.782917</td>\n",
       "      <td>0.448333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.244510</td>\n",
       "      <td>0.812922</td>\n",
       "      <td>0.460726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.238750</td>\n",
       "      <td>0.785833</td>\n",
       "      <td>0.448333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.244088</td>\n",
       "      <td>0.818412</td>\n",
       "      <td>0.460726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MLP</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.705833</td>\n",
       "      <td>0.448333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MLP</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.171453</td>\n",
       "      <td>0.724240</td>\n",
       "      <td>0.460726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MLP</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.163333</td>\n",
       "      <td>0.705833</td>\n",
       "      <td>0.448333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MLP</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.171030</td>\n",
       "      <td>0.724240</td>\n",
       "      <td>0.460726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MLP</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.705833</td>\n",
       "      <td>0.448333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MLP</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.170608</td>\n",
       "      <td>0.724240</td>\n",
       "      <td>0.248733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MLP</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.705833</td>\n",
       "      <td>0.448333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MLP</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.171030</td>\n",
       "      <td>0.724240</td>\n",
       "      <td>0.460726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>MLP</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.705833</td>\n",
       "      <td>0.448333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MLP</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.171030</td>\n",
       "      <td>0.724240</td>\n",
       "      <td>0.460726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MLP</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.705833</td>\n",
       "      <td>0.448333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MLP</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.171030</td>\n",
       "      <td>0.724240</td>\n",
       "      <td>0.460726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>MLP</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.705833</td>\n",
       "      <td>0.448333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>MLP</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.171453</td>\n",
       "      <td>0.724240</td>\n",
       "      <td>0.460726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>MLP</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.705833</td>\n",
       "      <td>0.448333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>MLP</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.171030</td>\n",
       "      <td>0.724240</td>\n",
       "      <td>0.460726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>CNN</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.303750</td>\n",
       "      <td>0.834583</td>\n",
       "      <td>0.473750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>CNN</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.355674</td>\n",
       "      <td>0.908306</td>\n",
       "      <td>0.488487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>CNN</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.282917</td>\n",
       "      <td>0.852917</td>\n",
       "      <td>0.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>CNN</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.254523</td>\n",
       "      <td>0.752056</td>\n",
       "      <td>0.435444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>CNN</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.324583</td>\n",
       "      <td>0.874167</td>\n",
       "      <td>0.456667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>CNN</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.285362</td>\n",
       "      <td>0.862253</td>\n",
       "      <td>0.451069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>CNN</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.284583</td>\n",
       "      <td>0.859583</td>\n",
       "      <td>0.457500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>CNN</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.285362</td>\n",
       "      <td>0.743832</td>\n",
       "      <td>0.443668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>CNN</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.345000</td>\n",
       "      <td>0.903750</td>\n",
       "      <td>0.460000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>CNN</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.364309</td>\n",
       "      <td>0.896793</td>\n",
       "      <td>0.507812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>CNN</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.257500</td>\n",
       "      <td>0.794583</td>\n",
       "      <td>0.455417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>CNN</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.164474</td>\n",
       "      <td>0.706826</td>\n",
       "      <td>0.449013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>CNN</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.327917</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.475000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>CNN</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.365543</td>\n",
       "      <td>0.917352</td>\n",
       "      <td>0.497533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>CNN</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.282500</td>\n",
       "      <td>0.809167</td>\n",
       "      <td>0.469167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>CNN</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.164474</td>\n",
       "      <td>0.706826</td>\n",
       "      <td>0.449013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model  Number of Hidden Layers  Batch Size Activation Function  \\\n",
       "0    MLP                        0          16                relu   \n",
       "1    MLP                        0          64                relu   \n",
       "2    MLP                        0          16             sigmoid   \n",
       "3    MLP                        0          64             sigmoid   \n",
       "4    MLP                        0          16                relu   \n",
       "5    MLP                        0          64                relu   \n",
       "6    MLP                        0          16             sigmoid   \n",
       "7    MLP                        0          64             sigmoid   \n",
       "8    MLP                        1          16                relu   \n",
       "9    MLP                        1          64                relu   \n",
       "10   MLP                        1          16             sigmoid   \n",
       "11   MLP                        1          64             sigmoid   \n",
       "12   MLP                        1          16                relu   \n",
       "13   MLP                        1          64                relu   \n",
       "14   MLP                        1          16             sigmoid   \n",
       "15   MLP                        1          64             sigmoid   \n",
       "16   MLP                        2          16                relu   \n",
       "17   MLP                        2          64                relu   \n",
       "18   MLP                        2          16             sigmoid   \n",
       "19   MLP                        2          64             sigmoid   \n",
       "20   MLP                        2          16                relu   \n",
       "21   MLP                        2          64                relu   \n",
       "22   MLP                        2          16             sigmoid   \n",
       "23   MLP                        2          64             sigmoid   \n",
       "24   CNN                        1          16                relu   \n",
       "25   CNN                        1          64                relu   \n",
       "26   CNN                        1          16             sigmoid   \n",
       "27   CNN                        1          64             sigmoid   \n",
       "28   CNN                        1          16                relu   \n",
       "29   CNN                        1          64                relu   \n",
       "30   CNN                        1          16             sigmoid   \n",
       "31   CNN                        1          64             sigmoid   \n",
       "32   CNN                        2          16                relu   \n",
       "33   CNN                        2          64                relu   \n",
       "34   CNN                        2          16             sigmoid   \n",
       "35   CNN                        2          64             sigmoid   \n",
       "36   CNN                        2          16                relu   \n",
       "37   CNN                        2          64                relu   \n",
       "38   CNN                        2          16             sigmoid   \n",
       "39   CNN                        2          64             sigmoid   \n",
       "\n",
       "    Learning Rate  Age Accuracy  Gender Accuracy  Accent Accuracy  \n",
       "0         0.00001      0.227917         0.709583         0.448333  \n",
       "1         0.00001      0.225084         0.727196         0.460726  \n",
       "2         0.00001      0.230000         0.708750         0.448333  \n",
       "3         0.00001      0.240709         0.724662         0.460726  \n",
       "4         0.00010      0.236667         0.782917         0.448333  \n",
       "5         0.00010      0.244510         0.812922         0.460726  \n",
       "6         0.00010      0.238750         0.785833         0.448333  \n",
       "7         0.00010      0.244088         0.818412         0.460726  \n",
       "8         0.00001      0.166667         0.705833         0.448333  \n",
       "9         0.00001      0.171453         0.724240         0.460726  \n",
       "10        0.00001      0.163333         0.705833         0.448333  \n",
       "11        0.00001      0.171030         0.724240         0.460726  \n",
       "12        0.00010      0.166667         0.705833         0.448333  \n",
       "13        0.00010      0.170608         0.724240         0.248733  \n",
       "14        0.00010      0.166667         0.705833         0.448333  \n",
       "15        0.00010      0.171030         0.724240         0.460726  \n",
       "16        0.00001      0.166667         0.705833         0.448333  \n",
       "17        0.00001      0.171030         0.724240         0.460726  \n",
       "18        0.00001      0.166667         0.705833         0.448333  \n",
       "19        0.00001      0.171030         0.724240         0.460726  \n",
       "20        0.00010      0.166667         0.705833         0.448333  \n",
       "21        0.00010      0.171453         0.724240         0.460726  \n",
       "22        0.00010      0.166667         0.705833         0.448333  \n",
       "23        0.00010      0.171030         0.724240         0.460726  \n",
       "24        0.00100      0.303750         0.834583         0.473750  \n",
       "25        0.00100      0.355674         0.908306         0.488487  \n",
       "26        0.00100      0.282917         0.852917         0.458333  \n",
       "27        0.00100      0.254523         0.752056         0.435444  \n",
       "28        0.00010      0.324583         0.874167         0.456667  \n",
       "29        0.00010      0.285362         0.862253         0.451069  \n",
       "30        0.00010      0.284583         0.859583         0.457500  \n",
       "31        0.00010      0.285362         0.743832         0.443668  \n",
       "32        0.00100      0.345000         0.903750         0.460000  \n",
       "33        0.00100      0.364309         0.896793         0.507812  \n",
       "34        0.00100      0.257500         0.794583         0.455417  \n",
       "35        0.00100      0.164474         0.706826         0.449013  \n",
       "36        0.00010      0.327917         0.900000         0.475000  \n",
       "37        0.00010      0.365543         0.917352         0.497533  \n",
       "38        0.00010      0.282500         0.809167         0.469167  \n",
       "39        0.00010      0.164474         0.706826         0.449013  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_excel('model_results.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, random_split, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    '''\n",
    "        Dataset class to replicate Pytorch Datasets\n",
    "        ____________________________________________\n",
    "\n",
    "        Parameters\n",
    "        ____________\n",
    "\n",
    "        image_dir : str\n",
    "            the directory contains images\n",
    "\n",
    "        image_paths : list[str]\n",
    "            the relative paths to image_dir\n",
    "\n",
    "        age : np.array\n",
    "            Age array\n",
    "\n",
    "        gender : np.array\n",
    "            Gender array\n",
    "\n",
    "        accent : np.array\n",
    "            Accent array\n",
    "\n",
    "    '''\n",
    "    def __init__(self, image_dir: str, \n",
    "                 image_paths: list[str], \n",
    "                 age: np.array, \n",
    "                 gender: np.array, \n",
    "                 accent: np.array):\n",
    "        self.image_dir = image_dir\n",
    "        self.image_paths = list(map(lambda p: os.path.join(image_dir, p), image_paths))\n",
    "        self.age = torch.Tensor(age)\n",
    "        self.gender = torch.Tensor(gender)\n",
    "        self.accent = torch.Tensor(accent)\n",
    "\n",
    "    def __getitem__(self, indices):\n",
    "        if isinstance(indices, int):\n",
    "            indices = slice(indices, indices+1)\n",
    "\n",
    "        return torch.Tensor(read_images(self.image_paths[indices], ratio=5)), \\\n",
    "                self.age[indices], \\\n",
    "                self.gender[indices], \\\n",
    "                self.accent[indices]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageDataset(image_dir='dataset_a3/voice_dataset/train/', \n",
    "                        image_paths=train_paths, \n",
    "                        age=train_age,\n",
    "                        gender=train_gender,\n",
    "                        accent=train_accent)\n",
    "\n",
    "test_dataset = ImageDataset(image_dir='dataset_a3/voice_dataset/test/', \n",
    "                        image_paths=test_paths, \n",
    "                        age=test_age,\n",
    "                        gender=test_gender,\n",
    "                        accent=test_accent)\n",
    "\n",
    "val_size = int(0.2 * len(train_dataset))\n",
    "train_size = len(train_dataset) - val_size\n",
    "\n",
    "# Use random_split to create training and validation datasets\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_16_cnn = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader_16_cnn = DataLoader(test_dataset, batch_size=16, shuffle=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hardmax(x):\n",
    "    return torch.argmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 hidden_cnn_layers,\n",
    "                 age_classes,\n",
    "                 gender_classes,\n",
    "                 accent_classes,\n",
    "                 activation_function) -> None:\n",
    "        super().__init__()\n",
    "        self.conv_layers = nn.ModuleList()\n",
    "        in_channels = 4\n",
    "        out_channels = in_channels*4\n",
    "        for _ in range(hidden_cnn_layers):\n",
    "            self.conv_layers.append(\n",
    "                nn.Conv2d(in_channels=in_channels, \n",
    "                           out_channels=out_channels, \n",
    "                           kernel_size=5, \n",
    "                           stride=1, \n",
    "                           padding=2)\n",
    "            )\n",
    "            in_channels = out_channels\n",
    "            out_channels *= 4\n",
    "        # 39, 94\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        dummy_input = torch.randn(1, 4, 61, 155)\n",
    "        self.fc1 = nn.Linear(self._get_conv_output_shape(dummy_input).shape[1], 512)\n",
    "        self.age = nn.Linear(512, len(age_classes))\n",
    "        self.gender = nn.Linear(512, len(gender_classes))\n",
    "        self.accent = nn.Linear(512, len(accent_classes))\n",
    "        assert activation_function == 'relu' or activation_function == 'sigmoid', 'Activation Layer must be relu or sigmoid.'\n",
    "        self.af = F.relu if activation_function == 'relu' else F.sigmoid\n",
    "    def _get_conv_output_shape(self, x):\n",
    "        for conv_layer in self.conv_layers:\n",
    "            x = conv_layer(x)\n",
    "            x = self.pool(x)\n",
    "        return x.view(x.size(0), -1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for conv in self.conv_layers:\n",
    "            x = self.af(conv(x))\n",
    "            x = self.pool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        age = self.age(x)\n",
    "        gender = self.gender(x)\n",
    "        accent = self.accent(x)\n",
    "\n",
    "        return age, gender, accent\n",
    "    \n",
    "\n",
    "    def train_model(self, train_loader, epochs, optimizer, criterion, val_loader=None):\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.to(device)\n",
    "        for _ in range(epochs):\n",
    "            self._run_epoch(train_loader, device, optimizer, criterion, \"Train\")\n",
    "\n",
    "            if val_loader is not None:\n",
    "                self._run_epoch(val_loader, device, optimizer, criterion, \"Validation\")\n",
    "\n",
    "\n",
    "    def _run_epoch(self, data_loader, device, optimizer, criterion, mode=\"Train\"):\n",
    "        if mode == 'Validation':\n",
    "            torch.set_grad_enabled(False)\n",
    "            self.eval()\n",
    "        else:\n",
    "            torch.set_grad_enabled(True)\n",
    "            self.train()\n",
    "        prefix = \"Epoch\" if mode == \"Train\" else \"Val\"\n",
    "        epoch_loss = 0\n",
    "        epoch_age_acc, epoch_gender_acc, epoch_accent_acc = 0, 0, 0\n",
    "\n",
    "        # Use tqdm to create a progress bar\n",
    "        for x, age_true, gender_true, accent_true in tqdm(data_loader):\n",
    "            x = torch.squeeze(x)\n",
    "            x = x.permute(0, 3, 1, 2)\n",
    "            x = x.to(device)\n",
    "\n",
    "            age_true = age_true.to(device).squeeze()\n",
    "            gender_true = gender_true.to(device).squeeze()\n",
    "            accent_true = accent_true.to(device).squeeze()\n",
    "            if mode == 'Train':\n",
    "                # Zero the gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            age_pred, gender_pred, accent_pred = self(x)\n",
    "\n",
    "            # Compute the loss\n",
    "            loss = criterion(age_pred, age_true) + criterion(gender_pred, gender_true) + criterion(accent_pred, accent_true)\n",
    "            \n",
    "            if mode == 'Train':\n",
    "                # Backward pass\n",
    "                loss.backward()\n",
    "\n",
    "                # Update weights\n",
    "                optimizer.step()\n",
    "\n",
    "            # Assuming age_true, age_pred are PyTorch tensors\n",
    "            age_true_numpy = hardmax(age_true).cpu().numpy()\n",
    "            age_pred_numpy = hardmax(age_pred).cpu().numpy()\n",
    "\n",
    "            # Now use accuracy_score with the NumPy arrays\n",
    "            age_accuracy = accuracy_score(age_true_numpy, age_pred_numpy)\n",
    "\n",
    "            # Repeat the same for gender and accent if needed\n",
    "            gender_true_numpy = hardmax(gender_true).cpu().numpy()\n",
    "            gender_pred_numpy = hardmax(gender_pred).cpu().numpy()\n",
    "            gender_accuracy = accuracy_score(gender_true_numpy, gender_pred_numpy)\n",
    "\n",
    "            accent_true_numpy = hardmax(accent_true).cpu().numpy()\n",
    "            accent_pred_numpy = hardmax(accent_pred).cpu().numpy()\n",
    "            \n",
    "            accent_accuracy = accuracy_score(accent_true_numpy, accent_pred_numpy)\n",
    "            epoch_loss += loss\n",
    "\n",
    "            epoch_age_acc += age_accuracy\n",
    "            epoch_gender_acc += gender_accuracy\n",
    "            epoch_accent_acc += accent_accuracy\n",
    "\n",
    "        epoch_loss /= len(data_loader)\n",
    "        epoch_age_acc /= len(data_loader)\n",
    "        epoch_gender_acc /= len(data_loader)\n",
    "        epoch_accent_acc /= len(data_loader)\n",
    "\n",
    "        logging.info(f'\\n{prefix} Loss: {epoch_loss:.4f}, Age Accuracy: {epoch_age_acc:.4f}, Gender Accuracy: {epoch_gender_acc:.4f}, Accent Accuracy: {epoch_accent_acc:.4f}')\n",
    "        logging.info('__________________________________________________________________________________')\n",
    "\n",
    "\n",
    "    def test(self, test_loader):\n",
    "        epoch_age_acc, epoch_gender_acc, epoch_accent_acc = 0, 0, 0\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.to(device)\n",
    "        # Use tqdm to create a progress bar\n",
    "        for x, age_true, gender_true, accent_true in tqdm(test_loader):\n",
    "            x = torch.squeeze(x)\n",
    "            x = x.permute(0, 3, 1, 2)\n",
    "            x = x.to(device)\n",
    "\n",
    "            age_true = age_true.to(device).squeeze()\n",
    "            gender_true = gender_true.to(device).squeeze()\n",
    "            accent_true = accent_true.to(device).squeeze()\n",
    "\n",
    "            age_pred, gender_pred, accent_pred = self(x)\n",
    "\n",
    "            # Assuming age_true, age_pred are PyTorch tensors\n",
    "            age_true_numpy = hardmax(age_true).cpu().numpy()\n",
    "            age_pred_numpy = hardmax(age_pred).cpu().numpy()\n",
    "\n",
    "            # Now use accuracy_score with the NumPy arrays\n",
    "            age_accuracy = accuracy_score(age_true_numpy, age_pred_numpy)\n",
    "\n",
    "            # Repeat the same for gender and accent if needed\n",
    "            gender_true_numpy = hardmax(gender_true).cpu().numpy()\n",
    "            gender_pred_numpy = hardmax(gender_pred).cpu().numpy()\n",
    "            gender_accuracy = accuracy_score(gender_true_numpy, gender_pred_numpy)\n",
    "\n",
    "            accent_true_numpy = hardmax(accent_true).cpu().numpy()\n",
    "            accent_pred_numpy = hardmax(accent_pred).cpu().numpy()\n",
    "            \n",
    "            accent_accuracy = accuracy_score(accent_true_numpy, accent_pred_numpy)\n",
    "\n",
    "            epoch_age_acc += age_accuracy\n",
    "            epoch_gender_acc += gender_accuracy\n",
    "            epoch_accent_acc += accent_accuracy\n",
    "\n",
    "        epoch_age_acc /= len(test_loader)\n",
    "        epoch_gender_acc /= len(test_loader)\n",
    "        epoch_accent_acc /= len(test_loader)\n",
    "\n",
    "        logging.info(f'\\Test Age Accuracy: {epoch_age_acc:.4f}, Gender Accuracy: {epoch_gender_acc:.4f}, Accent Accuracy: {epoch_accent_acc:.4f}')\n",
    "        logging.info('__________________________________________________________________________________')\n",
    "\n",
    "        return epoch_age_acc, epoch_gender_acc, epoch_accent_acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train and evaluate the model\n",
    "def train_and_evaluate_model_cnn(model_name, hidden_layer_size, batch_size, activation_function, learning_rate):\n",
    "    '''\n",
    "    Train and Evaluate function for CNN model.\n",
    "    Parameters:\n",
    "        model_name: Model's name will to save results\n",
    "        hidden_layer_Size: Size of Hidden Layers.\n",
    "        batch_size: Batch Size\n",
    "        activation_function, ReLU or Sigmoid activation Function\n",
    "        learning_rate: Learning rate alpha to write learning rates.\n",
    "\n",
    "    Returns:\n",
    "        Dictionary that contains information about model, training and accuracies. \n",
    "    '''\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    model = CNN(age_classes=train_df['age'].unique(),\n",
    "                gender_classes=train_df['gender'].unique(),\n",
    "                accent_classes=train_df['accent'].unique(),\n",
    "                activation_function=activation_function,\n",
    "                hidden_cnn_layers=hidden_layer_size)\n",
    "\n",
    "    optimizer = Adam(model.parameters(), lr=1e-3)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # Train the model for 5 epochs (you can adjust the number of epochs)\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size)\n",
    "    val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size)\n",
    "\n",
    "    model.train_model(train_loader=train_loader, \n",
    "                epochs=10,\n",
    "                criterion=criterion,\n",
    "                optimizer=optimizer,\n",
    "                val_loader=val_loader)\n",
    " \n",
    "    # Evaluate accuracy for each category (Age, Gender, Accent)\n",
    "    test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size)  # Provide your evaluation data\n",
    "    age_accuracy, gender_accuracy, accent_accuracy = model.test(test_loader)\n",
    "\n",
    "    # Return the results\n",
    "    return {\n",
    "        'Model': model_name,\n",
    "        'Number of Hidden Layers': hidden_layer_size,\n",
    "        'Batch Size': batch_size,\n",
    "        'Activation Function': activation_function,\n",
    "        'Learning Rate': learning_rate,\n",
    "        'Age Accuracy': age_accuracy,\n",
    "        'Gender Accuracy': gender_accuracy,\n",
    "        'Accent Accuracy': accent_accuracy\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configurations = [    \n",
    "    ('CNN', 1, 16, 'relu', 1e-3),\n",
    "    ('CNN', 1, 64, 'relu', 1e-3),\n",
    "    ('CNN', 1, 16, 'sigmoid', 1e-3),\n",
    "    ('CNN', 1, 64, 'sigmoid', 1e-3),\n",
    "    ('CNN', 1, 16, 'relu', 1e-4),\n",
    "    ('CNN', 1, 64, 'relu', 1e-4),\n",
    "    ('CNN', 1, 16, 'sigmoid', 1e-4),\n",
    "    ('CNN', 1, 64, 'sigmoid', 1e-4),\n",
    "\n",
    "    ('CNN', 2, 16, 'relu', 1e-3),\n",
    "    ('CNN', 2, 64, 'relu', 1e-3),\n",
    "    ('CNN', 2, 16, 'sigmoid', 1e-3),\n",
    "    ('CNN', 2, 64, 'sigmoid', 1e-3),\n",
    "    ('CNN', 2, 16, 'relu', 1e-4),\n",
    "    ('CNN', 2, 64, 'relu', 1e-4),\n",
    "    ('CNN', 2, 16, 'sigmoid', 1e-4),\n",
    "    ('CNN', 2, 64, 'sigmoid', 1e-4),\n",
    "]\n",
    "# model_configurations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, hidden_layer_size, batch_size, activation_function, learning_rate in model_configurations:\n",
    "    logging.info('////////////////////////////////////')\n",
    "    results = train_and_evaluate_model_cnn(model_name, hidden_layer_size, batch_size, activation_function, learning_rate)\n",
    "    results_df = pd.concat([results_df, pd.DataFrame([results], columns=results_df.columns)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Number of Hidden Layers</th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Activation Function</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Age Accuracy</th>\n",
       "      <th>Gender Accuracy</th>\n",
       "      <th>Accent Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.227917</td>\n",
       "      <td>0.709583</td>\n",
       "      <td>0.448333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.225084</td>\n",
       "      <td>0.727196</td>\n",
       "      <td>0.460726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.708750</td>\n",
       "      <td>0.448333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.240709</td>\n",
       "      <td>0.724662</td>\n",
       "      <td>0.460726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.236667</td>\n",
       "      <td>0.782917</td>\n",
       "      <td>0.448333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.244510</td>\n",
       "      <td>0.812922</td>\n",
       "      <td>0.460726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.238750</td>\n",
       "      <td>0.785833</td>\n",
       "      <td>0.448333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.244088</td>\n",
       "      <td>0.818412</td>\n",
       "      <td>0.460726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MLP</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.705833</td>\n",
       "      <td>0.448333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MLP</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.171453</td>\n",
       "      <td>0.724240</td>\n",
       "      <td>0.460726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MLP</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.163333</td>\n",
       "      <td>0.705833</td>\n",
       "      <td>0.448333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MLP</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.171030</td>\n",
       "      <td>0.724240</td>\n",
       "      <td>0.460726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MLP</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.705833</td>\n",
       "      <td>0.448333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MLP</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.170608</td>\n",
       "      <td>0.724240</td>\n",
       "      <td>0.248733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MLP</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.705833</td>\n",
       "      <td>0.448333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MLP</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.171030</td>\n",
       "      <td>0.724240</td>\n",
       "      <td>0.460726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>MLP</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.705833</td>\n",
       "      <td>0.448333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MLP</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.171030</td>\n",
       "      <td>0.724240</td>\n",
       "      <td>0.460726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MLP</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.705833</td>\n",
       "      <td>0.448333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MLP</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.171030</td>\n",
       "      <td>0.724240</td>\n",
       "      <td>0.460726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>MLP</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.705833</td>\n",
       "      <td>0.448333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>MLP</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.171453</td>\n",
       "      <td>0.724240</td>\n",
       "      <td>0.460726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>MLP</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.705833</td>\n",
       "      <td>0.448333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>MLP</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.171030</td>\n",
       "      <td>0.724240</td>\n",
       "      <td>0.460726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>CNN</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.303750</td>\n",
       "      <td>0.834583</td>\n",
       "      <td>0.473750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>CNN</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.355674</td>\n",
       "      <td>0.908306</td>\n",
       "      <td>0.488487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>CNN</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.282917</td>\n",
       "      <td>0.852917</td>\n",
       "      <td>0.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>CNN</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.254523</td>\n",
       "      <td>0.752056</td>\n",
       "      <td>0.435444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>CNN</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.324583</td>\n",
       "      <td>0.874167</td>\n",
       "      <td>0.456667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>CNN</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.285362</td>\n",
       "      <td>0.862253</td>\n",
       "      <td>0.451069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>CNN</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.284583</td>\n",
       "      <td>0.859583</td>\n",
       "      <td>0.457500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>CNN</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.285362</td>\n",
       "      <td>0.743832</td>\n",
       "      <td>0.443668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>CNN</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.345000</td>\n",
       "      <td>0.903750</td>\n",
       "      <td>0.460000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>CNN</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.364309</td>\n",
       "      <td>0.896793</td>\n",
       "      <td>0.507812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>CNN</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.257500</td>\n",
       "      <td>0.794583</td>\n",
       "      <td>0.455417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>CNN</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.164474</td>\n",
       "      <td>0.706826</td>\n",
       "      <td>0.449013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>CNN</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.327917</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.475000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>CNN</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.365543</td>\n",
       "      <td>0.917352</td>\n",
       "      <td>0.497533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>CNN</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.282500</td>\n",
       "      <td>0.809167</td>\n",
       "      <td>0.469167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>CNN</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.164474</td>\n",
       "      <td>0.706826</td>\n",
       "      <td>0.449013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model  Number of Hidden Layers  Batch Size Activation Function  \\\n",
       "0    MLP                        0          16                relu   \n",
       "1    MLP                        0          64                relu   \n",
       "2    MLP                        0          16             sigmoid   \n",
       "3    MLP                        0          64             sigmoid   \n",
       "4    MLP                        0          16                relu   \n",
       "5    MLP                        0          64                relu   \n",
       "6    MLP                        0          16             sigmoid   \n",
       "7    MLP                        0          64             sigmoid   \n",
       "8    MLP                        1          16                relu   \n",
       "9    MLP                        1          64                relu   \n",
       "10   MLP                        1          16             sigmoid   \n",
       "11   MLP                        1          64             sigmoid   \n",
       "12   MLP                        1          16                relu   \n",
       "13   MLP                        1          64                relu   \n",
       "14   MLP                        1          16             sigmoid   \n",
       "15   MLP                        1          64             sigmoid   \n",
       "16   MLP                        2          16                relu   \n",
       "17   MLP                        2          64                relu   \n",
       "18   MLP                        2          16             sigmoid   \n",
       "19   MLP                        2          64             sigmoid   \n",
       "20   MLP                        2          16                relu   \n",
       "21   MLP                        2          64                relu   \n",
       "22   MLP                        2          16             sigmoid   \n",
       "23   MLP                        2          64             sigmoid   \n",
       "24   CNN                        1          16                relu   \n",
       "25   CNN                        1          64                relu   \n",
       "26   CNN                        1          16             sigmoid   \n",
       "27   CNN                        1          64             sigmoid   \n",
       "28   CNN                        1          16                relu   \n",
       "29   CNN                        1          64                relu   \n",
       "30   CNN                        1          16             sigmoid   \n",
       "31   CNN                        1          64             sigmoid   \n",
       "32   CNN                        2          16                relu   \n",
       "33   CNN                        2          64                relu   \n",
       "34   CNN                        2          16             sigmoid   \n",
       "35   CNN                        2          64             sigmoid   \n",
       "36   CNN                        2          16                relu   \n",
       "37   CNN                        2          64                relu   \n",
       "38   CNN                        2          16             sigmoid   \n",
       "39   CNN                        2          64             sigmoid   \n",
       "\n",
       "    Learning Rate  Age Accuracy  Gender Accuracy  Accent Accuracy  \n",
       "0         0.00001      0.227917         0.709583         0.448333  \n",
       "1         0.00001      0.225084         0.727196         0.460726  \n",
       "2         0.00001      0.230000         0.708750         0.448333  \n",
       "3         0.00001      0.240709         0.724662         0.460726  \n",
       "4         0.00010      0.236667         0.782917         0.448333  \n",
       "5         0.00010      0.244510         0.812922         0.460726  \n",
       "6         0.00010      0.238750         0.785833         0.448333  \n",
       "7         0.00010      0.244088         0.818412         0.460726  \n",
       "8         0.00001      0.166667         0.705833         0.448333  \n",
       "9         0.00001      0.171453         0.724240         0.460726  \n",
       "10        0.00001      0.163333         0.705833         0.448333  \n",
       "11        0.00001      0.171030         0.724240         0.460726  \n",
       "12        0.00010      0.166667         0.705833         0.448333  \n",
       "13        0.00010      0.170608         0.724240         0.248733  \n",
       "14        0.00010      0.166667         0.705833         0.448333  \n",
       "15        0.00010      0.171030         0.724240         0.460726  \n",
       "16        0.00001      0.166667         0.705833         0.448333  \n",
       "17        0.00001      0.171030         0.724240         0.460726  \n",
       "18        0.00001      0.166667         0.705833         0.448333  \n",
       "19        0.00001      0.171030         0.724240         0.460726  \n",
       "20        0.00010      0.166667         0.705833         0.448333  \n",
       "21        0.00010      0.171453         0.724240         0.460726  \n",
       "22        0.00010      0.166667         0.705833         0.448333  \n",
       "23        0.00010      0.171030         0.724240         0.460726  \n",
       "24        0.00100      0.303750         0.834583         0.473750  \n",
       "25        0.00100      0.355674         0.908306         0.488487  \n",
       "26        0.00100      0.282917         0.852917         0.458333  \n",
       "27        0.00100      0.254523         0.752056         0.435444  \n",
       "28        0.00010      0.324583         0.874167         0.456667  \n",
       "29        0.00010      0.285362         0.862253         0.451069  \n",
       "30        0.00010      0.284583         0.859583         0.457500  \n",
       "31        0.00010      0.285362         0.743832         0.443668  \n",
       "32        0.00100      0.345000         0.903750         0.460000  \n",
       "33        0.00100      0.364309         0.896793         0.507812  \n",
       "34        0.00100      0.257500         0.794583         0.455417  \n",
       "35        0.00100      0.164474         0.706826         0.449013  \n",
       "36        0.00010      0.327917         0.900000         0.475000  \n",
       "37        0.00010      0.365543         0.917352         0.497533  \n",
       "38        0.00010      0.282500         0.809167         0.469167  \n",
       "39        0.00010      0.164474         0.706826         0.449013  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_excel('model_results.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze\n",
    "\n",
    "- We pretrained our models 10 epoch and most of them can still learn something, but for sake of our research lets assume these results are descent.\n",
    "\n",
    "- When we look into the table there are somethings that are apparent.\n",
    "\n",
    "    - Relu is more effective activation function for CNN than sigmoid is, but for MLP they seem to be showing equivalent performance.\n",
    "\n",
    "    - CNN outperformed MLP for the most cases.\n",
    "\n",
    "    - Gender looks like the easiest one to learn but as the data may be unevenly distributed we need to check it first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age\n",
      "twenties    1600\n",
      "thirties    1600\n",
      "sixties     1600\n",
      "fifties     1600\n",
      "fourties    1600\n",
      "teens       1600\n",
      "Name: count, dtype: int64\n",
      "-------\n",
      "gender\n",
      "male      6786\n",
      "female    2706\n",
      "other      108\n",
      "Name: count, dtype: int64\n",
      "-------\n",
      "accent\n",
      "us                4477\n",
      "england           2206\n",
      "canada             643\n",
      "australia          610\n",
      "indian             562\n",
      "scotland           288\n",
      "newzealand         262\n",
      "african            209\n",
      "ireland            145\n",
      "wales               51\n",
      "malaysia            47\n",
      "philippines         37\n",
      "singapore           24\n",
      "bermuda             16\n",
      "hongkong            15\n",
      "southatlandtic       8\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "age_distribution = train_df['age'].value_counts()\n",
    "gender_distribution = train_df['gender'].value_counts()\n",
    "accent_distribution = train_df['accent'].value_counts()\n",
    "print(str(age_distribution) + '\\n-------\\n' + str(gender_distribution) + '\\n-------\\n' + str(accent_distribution))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems ages are distributed evenly but gender is biased to male and accent is biased to us. So, we can think the models that do not represent good results are memorizing the distribution. Sometimes these results with models that are worse than rendom distribution.\n",
    "\n",
    "##### Analyzing Number of Hidden Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_n0 = results_df[results_df['Number of Hidden Layers'] == 0].describe()\n",
    "analyze_n1 = results_df[results_df['Number of Hidden Layers'] == 1].describe()\n",
    "analyze_n2 = results_df[results_df['Number of Hidden Layers'] == 2].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Hidden Layers</th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Age Accuracy</th>\n",
       "      <th>Gender Accuracy</th>\n",
       "      <th>Accent Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.235966</td>\n",
       "      <td>0.758784</td>\n",
       "      <td>0.454530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>25.657079</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.007450</td>\n",
       "      <td>0.046116</td>\n",
       "      <td>0.006624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.225084</td>\n",
       "      <td>0.708750</td>\n",
       "      <td>0.448333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.229479</td>\n",
       "      <td>0.720892</td>\n",
       "      <td>0.448333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.237708</td>\n",
       "      <td>0.755056</td>\n",
       "      <td>0.454530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.241554</td>\n",
       "      <td>0.792606</td>\n",
       "      <td>0.460726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.244510</td>\n",
       "      <td>0.818412</td>\n",
       "      <td>0.460726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Number of Hidden Layers  Batch Size  Learning Rate  Age Accuracy  \\\n",
       "count                      8.0    8.000000       8.000000      8.000000   \n",
       "mean                       0.0   40.000000       0.000055      0.235966   \n",
       "std                        0.0   25.657079       0.000048      0.007450   \n",
       "min                        0.0   16.000000       0.000010      0.225084   \n",
       "25%                        0.0   16.000000       0.000010      0.229479   \n",
       "50%                        0.0   40.000000       0.000055      0.237708   \n",
       "75%                        0.0   64.000000       0.000100      0.241554   \n",
       "max                        0.0   64.000000       0.000100      0.244510   \n",
       "\n",
       "       Gender Accuracy  Accent Accuracy  \n",
       "count         8.000000         8.000000  \n",
       "mean          0.758784         0.454530  \n",
       "std           0.046116         0.006624  \n",
       "min           0.708750         0.448333  \n",
       "25%           0.720892         0.448333  \n",
       "50%           0.755056         0.454530  \n",
       "75%           0.792606         0.460726  \n",
       "max           0.818412         0.460726  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_n0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Hidden Layers</th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Age Accuracy</th>\n",
       "      <th>Gender Accuracy</th>\n",
       "      <th>Accent Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16.0</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.0</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.232763</td>\n",
       "      <td>0.775499</td>\n",
       "      <td>0.443073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>24.787093</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.069740</td>\n",
       "      <td>0.074355</td>\n",
       "      <td>0.053270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.163333</td>\n",
       "      <td>0.705833</td>\n",
       "      <td>0.248733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.169623</td>\n",
       "      <td>0.719638</td>\n",
       "      <td>0.448333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.212988</td>\n",
       "      <td>0.734036</td>\n",
       "      <td>0.453868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.285362</td>\n",
       "      <td>0.854584</td>\n",
       "      <td>0.460726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.0</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.355674</td>\n",
       "      <td>0.908306</td>\n",
       "      <td>0.488487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Number of Hidden Layers  Batch Size  Learning Rate  Age Accuracy  \\\n",
       "count                     16.0   16.000000      16.000000     16.000000   \n",
       "mean                       1.0   40.000000       0.000303      0.232763   \n",
       "std                        0.0   24.787093       0.000418      0.069740   \n",
       "min                        1.0   16.000000       0.000010      0.163333   \n",
       "25%                        1.0   16.000000       0.000077      0.169623   \n",
       "50%                        1.0   40.000000       0.000100      0.212988   \n",
       "75%                        1.0   64.000000       0.000325      0.285362   \n",
       "max                        1.0   64.000000       0.001000      0.355674   \n",
       "\n",
       "       Gender Accuracy  Accent Accuracy  \n",
       "count        16.000000        16.000000  \n",
       "mean          0.775499         0.443073  \n",
       "std           0.074355         0.053270  \n",
       "min           0.705833         0.248733  \n",
       "25%           0.719638         0.448333  \n",
       "50%           0.734036         0.453868  \n",
       "75%           0.854584         0.460726  \n",
       "max           0.908306         0.488487  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_n1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Hidden Layers</th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Age Accuracy</th>\n",
       "      <th>Gender Accuracy</th>\n",
       "      <th>Accent Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16.0</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.0</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.226433</td>\n",
       "      <td>0.772224</td>\n",
       "      <td>0.462450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>24.787093</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.082067</td>\n",
       "      <td>0.084642</td>\n",
       "      <td>0.017733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.0</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.164474</td>\n",
       "      <td>0.705833</td>\n",
       "      <td>0.448333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.0</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.706578</td>\n",
       "      <td>0.448843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.0</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.171030</td>\n",
       "      <td>0.724240</td>\n",
       "      <td>0.460363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.0</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.293854</td>\n",
       "      <td>0.831073</td>\n",
       "      <td>0.462836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.0</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.365543</td>\n",
       "      <td>0.917352</td>\n",
       "      <td>0.507812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Number of Hidden Layers  Batch Size  Learning Rate  Age Accuracy  \\\n",
       "count                     16.0   16.000000      16.000000     16.000000   \n",
       "mean                       2.0   40.000000       0.000303      0.226433   \n",
       "std                        0.0   24.787093       0.000418      0.082067   \n",
       "min                        2.0   16.000000       0.000010      0.164474   \n",
       "25%                        2.0   16.000000       0.000077      0.166667   \n",
       "50%                        2.0   40.000000       0.000100      0.171030   \n",
       "75%                        2.0   64.000000       0.000325      0.293854   \n",
       "max                        2.0   64.000000       0.001000      0.365543   \n",
       "\n",
       "       Gender Accuracy  Accent Accuracy  \n",
       "count        16.000000        16.000000  \n",
       "mean          0.772224         0.462450  \n",
       "std           0.084642         0.017733  \n",
       "min           0.705833         0.448333  \n",
       "25%           0.706578         0.448843  \n",
       "50%           0.724240         0.460363  \n",
       "75%           0.831073         0.462836  \n",
       "max           0.917352         0.507812  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_n2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The tables above show us the affect of Number of Hidden Layers.\n",
    "\n",
    "- 0 Layered model only was in MLP, but it performed well even equivalent or better to 1 Layer and 2 Layer models in average and min values.\n",
    "\n",
    "- 2 Layered models performs slightly better than 1 layered ones. And it can perform well if the models are more trained.\n",
    "\n",
    "- CNN models are outperformed but it seems in MLP part 0 layered model learned faster and more robust. Lets check 1 and 2 Layered CNNs and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_n1_MLP = results_df[(results_df['Number of Hidden Layers'] == 1) & (results_df['Model'] == 'MLP')].describe()\n",
    "analyze_n2_MLP = results_df[(results_df['Number of Hidden Layers'] == 2) & (results_df['Model'] == 'MLP')].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Hidden Layers</th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Age Accuracy</th>\n",
       "      <th>Gender Accuracy</th>\n",
       "      <th>Accent Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.0</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.168432</td>\n",
       "      <td>0.715037</td>\n",
       "      <td>0.428031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>25.657079</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.002993</td>\n",
       "      <td>0.009839</td>\n",
       "      <td>0.072706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.163333</td>\n",
       "      <td>0.705833</td>\n",
       "      <td>0.248733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.705833</td>\n",
       "      <td>0.448333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.168637</td>\n",
       "      <td>0.715037</td>\n",
       "      <td>0.448333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.171030</td>\n",
       "      <td>0.724240</td>\n",
       "      <td>0.460726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.0</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.171453</td>\n",
       "      <td>0.724240</td>\n",
       "      <td>0.460726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Number of Hidden Layers  Batch Size  Learning Rate  Age Accuracy  \\\n",
       "count                      8.0    8.000000       8.000000      8.000000   \n",
       "mean                       1.0   40.000000       0.000055      0.168432   \n",
       "std                        0.0   25.657079       0.000048      0.002993   \n",
       "min                        1.0   16.000000       0.000010      0.163333   \n",
       "25%                        1.0   16.000000       0.000010      0.166667   \n",
       "50%                        1.0   40.000000       0.000055      0.168637   \n",
       "75%                        1.0   64.000000       0.000100      0.171030   \n",
       "max                        1.0   64.000000       0.000100      0.171453   \n",
       "\n",
       "       Gender Accuracy  Accent Accuracy  \n",
       "count         8.000000         8.000000  \n",
       "mean          0.715037         0.428031  \n",
       "std           0.009839         0.072706  \n",
       "min           0.705833         0.248733  \n",
       "25%           0.705833         0.448333  \n",
       "50%           0.715037         0.448333  \n",
       "75%           0.724240         0.460726  \n",
       "max           0.724240         0.460726  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_n1_MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Hidden Layers</th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Age Accuracy</th>\n",
       "      <th>Gender Accuracy</th>\n",
       "      <th>Accent Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.0</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.168901</td>\n",
       "      <td>0.715037</td>\n",
       "      <td>0.454530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>25.657079</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.002393</td>\n",
       "      <td>0.009839</td>\n",
       "      <td>0.006624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.0</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.705833</td>\n",
       "      <td>0.448333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.0</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.705833</td>\n",
       "      <td>0.448333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.0</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.168849</td>\n",
       "      <td>0.715037</td>\n",
       "      <td>0.454530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.0</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.171030</td>\n",
       "      <td>0.724240</td>\n",
       "      <td>0.460726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.0</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.171453</td>\n",
       "      <td>0.724240</td>\n",
       "      <td>0.460726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Number of Hidden Layers  Batch Size  Learning Rate  Age Accuracy  \\\n",
       "count                      8.0    8.000000       8.000000      8.000000   \n",
       "mean                       2.0   40.000000       0.000055      0.168901   \n",
       "std                        0.0   25.657079       0.000048      0.002393   \n",
       "min                        2.0   16.000000       0.000010      0.166667   \n",
       "25%                        2.0   16.000000       0.000010      0.166667   \n",
       "50%                        2.0   40.000000       0.000055      0.168849   \n",
       "75%                        2.0   64.000000       0.000100      0.171030   \n",
       "max                        2.0   64.000000       0.000100      0.171453   \n",
       "\n",
       "       Gender Accuracy  Accent Accuracy  \n",
       "count         8.000000         8.000000  \n",
       "mean          0.715037         0.454530  \n",
       "std           0.009839         0.006624  \n",
       "min           0.705833         0.448333  \n",
       "25%           0.705833         0.448333  \n",
       "50%           0.715037         0.454530  \n",
       "75%           0.724240         0.460726  \n",
       "max           0.724240         0.460726  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_n2_MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- on MLP context 1 Layer and 2 Layer shows mostly similar results.\n",
    "\n",
    "- 0 Layered MLP outperformed these both with training 10 epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_n1_CNN = results_df[(results_df['Number of Hidden Layers'] == 1) & (results_df['Model'] == 'CNN')].describe()\n",
    "analyze_n2_CNN = results_df[(results_df['Number of Hidden Layers'] == 2) & (results_df['Model'] == 'CNN')].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Hidden Layers</th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Age Accuracy</th>\n",
       "      <th>Gender Accuracy</th>\n",
       "      <th>Accent Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.0</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>0.297094</td>\n",
       "      <td>0.835962</td>\n",
       "      <td>0.458115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>25.657079</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>0.030884</td>\n",
       "      <td>0.058260</td>\n",
       "      <td>0.016655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.254523</td>\n",
       "      <td>0.743832</td>\n",
       "      <td>0.435444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.284166</td>\n",
       "      <td>0.813951</td>\n",
       "      <td>0.449219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>0.285362</td>\n",
       "      <td>0.856250</td>\n",
       "      <td>0.457083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.308958</td>\n",
       "      <td>0.865232</td>\n",
       "      <td>0.462187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.0</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.355674</td>\n",
       "      <td>0.908306</td>\n",
       "      <td>0.488487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Number of Hidden Layers  Batch Size  Learning Rate  Age Accuracy  \\\n",
       "count                      8.0    8.000000       8.000000      8.000000   \n",
       "mean                       1.0   40.000000       0.000550      0.297094   \n",
       "std                        0.0   25.657079       0.000481      0.030884   \n",
       "min                        1.0   16.000000       0.000100      0.254523   \n",
       "25%                        1.0   16.000000       0.000100      0.284166   \n",
       "50%                        1.0   40.000000       0.000550      0.285362   \n",
       "75%                        1.0   64.000000       0.001000      0.308958   \n",
       "max                        1.0   64.000000       0.001000      0.355674   \n",
       "\n",
       "       Gender Accuracy  Accent Accuracy  \n",
       "count         8.000000         8.000000  \n",
       "mean          0.835962         0.458115  \n",
       "std           0.058260         0.016655  \n",
       "min           0.743832         0.435444  \n",
       "25%           0.813951         0.449219  \n",
       "50%           0.856250         0.457083  \n",
       "75%           0.865232         0.462187  \n",
       "max           0.908306         0.488487  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_n1_CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Hidden Layers</th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Age Accuracy</th>\n",
       "      <th>Gender Accuracy</th>\n",
       "      <th>Accent Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.0</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>0.283965</td>\n",
       "      <td>0.829412</td>\n",
       "      <td>0.470369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>25.657079</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>0.082830</td>\n",
       "      <td>0.088204</td>\n",
       "      <td>0.022058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.0</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.164474</td>\n",
       "      <td>0.706826</td>\n",
       "      <td>0.449013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.0</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.234243</td>\n",
       "      <td>0.772644</td>\n",
       "      <td>0.453816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.0</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>0.305208</td>\n",
       "      <td>0.852980</td>\n",
       "      <td>0.464583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.0</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.349827</td>\n",
       "      <td>0.900938</td>\n",
       "      <td>0.480633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.0</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.365543</td>\n",
       "      <td>0.917352</td>\n",
       "      <td>0.507812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Number of Hidden Layers  Batch Size  Learning Rate  Age Accuracy  \\\n",
       "count                      8.0    8.000000       8.000000      8.000000   \n",
       "mean                       2.0   40.000000       0.000550      0.283965   \n",
       "std                        0.0   25.657079       0.000481      0.082830   \n",
       "min                        2.0   16.000000       0.000100      0.164474   \n",
       "25%                        2.0   16.000000       0.000100      0.234243   \n",
       "50%                        2.0   40.000000       0.000550      0.305208   \n",
       "75%                        2.0   64.000000       0.001000      0.349827   \n",
       "max                        2.0   64.000000       0.001000      0.365543   \n",
       "\n",
       "       Gender Accuracy  Accent Accuracy  \n",
       "count         8.000000         8.000000  \n",
       "mean          0.829412         0.470369  \n",
       "std           0.088204         0.022058  \n",
       "min           0.706826         0.449013  \n",
       "25%           0.772644         0.453816  \n",
       "50%           0.852980         0.464583  \n",
       "75%           0.900938         0.480633  \n",
       "max           0.917352         0.507812  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_n2_CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2 layered CNN and 1 layered CNN shows similar outcome, but standard deviation of 2 Layered CNN is much more than 1 Layered have.\n",
    "\n",
    "- This indicates, 2 layered CNN is more diverse than 1 Layered, it is because, it is more slow learner than 1 Layered yet more robust. \n",
    "\n",
    "- Some of models did not learn much in 10 epochs but some of models outperform 1 Layered CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analyzing Learning Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_lr_1e5 = results_df[results_df['Learning Rate'] == 1e-5].describe()\n",
    "analyze_lr_1e4_MLP = results_df[(results_df['Learning Rate'] == 1e-4) & (results_df['Model'] == 'MLP')].describe()\n",
    "analyze_lr_1e4_CNN = results_df[(results_df['Learning Rate'] == 1e-4) & (results_df['Model'] == 'CNN')].describe()\n",
    "analyze_lr_1e3 = results_df[results_df['Learning Rate'] == 1e-3].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Hidden Layers</th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Age Accuracy</th>\n",
       "      <th>Gender Accuracy</th>\n",
       "      <th>Accent Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.00000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.189299</td>\n",
       "      <td>0.715874</td>\n",
       "      <td>0.454530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.852803</td>\n",
       "      <td>25.067182</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.031046</td>\n",
       "      <td>0.009434</td>\n",
       "      <td>0.006472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.163333</td>\n",
       "      <td>0.705833</td>\n",
       "      <td>0.448333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.705833</td>\n",
       "      <td>0.448333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.171030</td>\n",
       "      <td>0.716912</td>\n",
       "      <td>0.454530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.225793</td>\n",
       "      <td>0.724240</td>\n",
       "      <td>0.460726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.240709</td>\n",
       "      <td>0.727196</td>\n",
       "      <td>0.460726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Number of Hidden Layers  Batch Size  Learning Rate  Age Accuracy  \\\n",
       "count                12.000000   12.000000       12.00000     12.000000   \n",
       "mean                  1.000000   40.000000        0.00001      0.189299   \n",
       "std                   0.852803   25.067182        0.00000      0.031046   \n",
       "min                   0.000000   16.000000        0.00001      0.163333   \n",
       "25%                   0.000000   16.000000        0.00001      0.166667   \n",
       "50%                   1.000000   40.000000        0.00001      0.171030   \n",
       "75%                   2.000000   64.000000        0.00001      0.225793   \n",
       "max                   2.000000   64.000000        0.00001      0.240709   \n",
       "\n",
       "       Gender Accuracy  Accent Accuracy  \n",
       "count        12.000000        12.000000  \n",
       "mean          0.715874         0.454530  \n",
       "std           0.009434         0.006472  \n",
       "min           0.705833         0.448333  \n",
       "25%           0.705833         0.448333  \n",
       "50%           0.716912         0.454530  \n",
       "75%           0.724240         0.460726  \n",
       "max           0.727196         0.460726  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_lr_1e5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Hidden Layers</th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Age Accuracy</th>\n",
       "      <th>Gender Accuracy</th>\n",
       "      <th>Accent Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.0000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.192900</td>\n",
       "      <td>0.743365</td>\n",
       "      <td>0.436864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.852803</td>\n",
       "      <td>25.067182</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.035634</td>\n",
       "      <td>0.043626</td>\n",
       "      <td>0.059566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.705833</td>\n",
       "      <td>0.248733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.705833</td>\n",
       "      <td>0.448333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.171030</td>\n",
       "      <td>0.724240</td>\n",
       "      <td>0.448333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.237188</td>\n",
       "      <td>0.783646</td>\n",
       "      <td>0.460726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.244510</td>\n",
       "      <td>0.818412</td>\n",
       "      <td>0.460726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Number of Hidden Layers  Batch Size  Learning Rate  Age Accuracy  \\\n",
       "count                12.000000   12.000000        12.0000     12.000000   \n",
       "mean                  1.000000   40.000000         0.0001      0.192900   \n",
       "std                   0.852803   25.067182         0.0000      0.035634   \n",
       "min                   0.000000   16.000000         0.0001      0.166667   \n",
       "25%                   0.000000   16.000000         0.0001      0.166667   \n",
       "50%                   1.000000   40.000000         0.0001      0.171030   \n",
       "75%                   2.000000   64.000000         0.0001      0.237188   \n",
       "max                   2.000000   64.000000         0.0001      0.244510   \n",
       "\n",
       "       Gender Accuracy  Accent Accuracy  \n",
       "count        12.000000        12.000000  \n",
       "mean          0.743365         0.436864  \n",
       "std           0.043626         0.059566  \n",
       "min           0.705833         0.248733  \n",
       "25%           0.705833         0.448333  \n",
       "50%           0.724240         0.448333  \n",
       "75%           0.783646         0.460726  \n",
       "max           0.818412         0.460726  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_lr_1e4_MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can see on the table 10**(-4) learning rate performs better than 10**(-5) learning rate.\n",
    "\n",
    "- The Standard deviation for 10**(-4) learning rate is higher.\n",
    "\n",
    "- But, 10**(-4) learning rate results have outlier(s) on accent accuracy, and it affected standard deviation more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Hidden Layers</th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Age Accuracy</th>\n",
       "      <th>Gender Accuracy</th>\n",
       "      <th>Accent Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.0000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.500000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.290040</td>\n",
       "      <td>0.834147</td>\n",
       "      <td>0.462452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.534522</td>\n",
       "      <td>25.657079</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.058829</td>\n",
       "      <td>0.074919</td>\n",
       "      <td>0.017543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.164474</td>\n",
       "      <td>0.706826</td>\n",
       "      <td>0.443668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.284062</td>\n",
       "      <td>0.792833</td>\n",
       "      <td>0.450555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.500000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.285362</td>\n",
       "      <td>0.860918</td>\n",
       "      <td>0.457083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.325416</td>\n",
       "      <td>0.880625</td>\n",
       "      <td>0.470625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.365543</td>\n",
       "      <td>0.917352</td>\n",
       "      <td>0.497533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Number of Hidden Layers  Batch Size  Learning Rate  Age Accuracy  \\\n",
       "count                 8.000000    8.000000         8.0000      8.000000   \n",
       "mean                  1.500000   40.000000         0.0001      0.290040   \n",
       "std                   0.534522   25.657079         0.0000      0.058829   \n",
       "min                   1.000000   16.000000         0.0001      0.164474   \n",
       "25%                   1.000000   16.000000         0.0001      0.284062   \n",
       "50%                   1.500000   40.000000         0.0001      0.285362   \n",
       "75%                   2.000000   64.000000         0.0001      0.325416   \n",
       "max                   2.000000   64.000000         0.0001      0.365543   \n",
       "\n",
       "       Gender Accuracy  Accent Accuracy  \n",
       "count         8.000000         8.000000  \n",
       "mean          0.834147         0.462452  \n",
       "std           0.074919         0.017543  \n",
       "min           0.706826         0.443668  \n",
       "25%           0.792833         0.450555  \n",
       "50%           0.860918         0.457083  \n",
       "75%           0.880625         0.470625  \n",
       "max           0.917352         0.497533  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_lr_1e4_CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Hidden Layers</th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Age Accuracy</th>\n",
       "      <th>Gender Accuracy</th>\n",
       "      <th>Accent Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.500000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.291018</td>\n",
       "      <td>0.831227</td>\n",
       "      <td>0.466032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.534522</td>\n",
       "      <td>25.657079</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.066722</td>\n",
       "      <td>0.074707</td>\n",
       "      <td>0.023124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.164474</td>\n",
       "      <td>0.706826</td>\n",
       "      <td>0.435444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.256756</td>\n",
       "      <td>0.783951</td>\n",
       "      <td>0.453816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.500000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.293334</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.459167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.347668</td>\n",
       "      <td>0.898532</td>\n",
       "      <td>0.477434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.364309</td>\n",
       "      <td>0.908306</td>\n",
       "      <td>0.507812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Number of Hidden Layers  Batch Size  Learning Rate  Age Accuracy  \\\n",
       "count                 8.000000    8.000000          8.000      8.000000   \n",
       "mean                  1.500000   40.000000          0.001      0.291018   \n",
       "std                   0.534522   25.657079          0.000      0.066722   \n",
       "min                   1.000000   16.000000          0.001      0.164474   \n",
       "25%                   1.000000   16.000000          0.001      0.256756   \n",
       "50%                   1.500000   40.000000          0.001      0.293334   \n",
       "75%                   2.000000   64.000000          0.001      0.347668   \n",
       "max                   2.000000   64.000000          0.001      0.364309   \n",
       "\n",
       "       Gender Accuracy  Accent Accuracy  \n",
       "count         8.000000         8.000000  \n",
       "mean          0.831227         0.466032  \n",
       "std           0.074707         0.023124  \n",
       "min           0.706826         0.435444  \n",
       "25%           0.783951         0.453816  \n",
       "50%           0.843750         0.459167  \n",
       "75%           0.898532         0.477434  \n",
       "max           0.908306         0.507812  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_lr_1e3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CNN's we tried 10**(-3) and 10**(-4) learning rates.\n",
    "\n",
    "- 10**(-4) performs better than 10**(-3) in age category, almost equal in Gender category, and worse in Accent category. and overall they perform similar.\n",
    "\n",
    "##### Analyzing Batch Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_batch16_MLP = results_df[(results_df['Batch Size'] == 16) & (results_df['Model'] == 'MLP')].describe()\n",
    "analyze_batch16_CNN = results_df[(results_df['Batch Size'] == 16) & (results_df['Model'] == 'CNN')].describe()\n",
    "analyze_batch64_MLP = results_df[(results_df['Batch Size'] == 64) & (results_df['Model'] == 'MLP')].describe()\n",
    "analyze_batch64_CNN = results_df[(results_df['Batch Size'] == 64) & (results_df['Model'] == 'CNN')].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Hidden Layers</th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Age Accuracy</th>\n",
       "      <th>Gender Accuracy</th>\n",
       "      <th>Accent Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.188611</td>\n",
       "      <td>0.719479</td>\n",
       "      <td>0.448333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.852803</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.033154</td>\n",
       "      <td>0.030346</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.163333</td>\n",
       "      <td>0.705833</td>\n",
       "      <td>0.448333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.705833</td>\n",
       "      <td>0.448333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.705833</td>\n",
       "      <td>0.448333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.228438</td>\n",
       "      <td>0.708958</td>\n",
       "      <td>0.448333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.238750</td>\n",
       "      <td>0.785833</td>\n",
       "      <td>0.448333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Number of Hidden Layers  Batch Size  Learning Rate  Age Accuracy  \\\n",
       "count                12.000000        12.0      12.000000     12.000000   \n",
       "mean                  1.000000        16.0       0.000055      0.188611   \n",
       "std                   0.852803         0.0       0.000047      0.033154   \n",
       "min                   0.000000        16.0       0.000010      0.163333   \n",
       "25%                   0.000000        16.0       0.000010      0.166667   \n",
       "50%                   1.000000        16.0       0.000055      0.166667   \n",
       "75%                   2.000000        16.0       0.000100      0.228438   \n",
       "max                   2.000000        16.0       0.000100      0.238750   \n",
       "\n",
       "       Gender Accuracy  Accent Accuracy  \n",
       "count        12.000000        12.000000  \n",
       "mean          0.719479         0.448333  \n",
       "std           0.030346         0.000000  \n",
       "min           0.705833         0.448333  \n",
       "25%           0.705833         0.448333  \n",
       "50%           0.705833         0.448333  \n",
       "75%           0.708958         0.448333  \n",
       "max           0.785833         0.448333  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_batch16_MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Hidden Layers</th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Age Accuracy</th>\n",
       "      <th>Gender Accuracy</th>\n",
       "      <th>Accent Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.193588</td>\n",
       "      <td>0.739759</td>\n",
       "      <td>0.443060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.852803</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.033586</td>\n",
       "      <td>0.035486</td>\n",
       "      <td>0.061197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.170608</td>\n",
       "      <td>0.724240</td>\n",
       "      <td>0.248733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.171030</td>\n",
       "      <td>0.724240</td>\n",
       "      <td>0.460726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.171242</td>\n",
       "      <td>0.724240</td>\n",
       "      <td>0.460726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.228991</td>\n",
       "      <td>0.725296</td>\n",
       "      <td>0.460726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.244510</td>\n",
       "      <td>0.818412</td>\n",
       "      <td>0.460726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Number of Hidden Layers  Batch Size  Learning Rate  Age Accuracy  \\\n",
       "count                12.000000        12.0      12.000000     12.000000   \n",
       "mean                  1.000000        64.0       0.000055      0.193588   \n",
       "std                   0.852803         0.0       0.000047      0.033586   \n",
       "min                   0.000000        64.0       0.000010      0.170608   \n",
       "25%                   0.000000        64.0       0.000010      0.171030   \n",
       "50%                   1.000000        64.0       0.000055      0.171242   \n",
       "75%                   2.000000        64.0       0.000100      0.228991   \n",
       "max                   2.000000        64.0       0.000100      0.244510   \n",
       "\n",
       "       Gender Accuracy  Accent Accuracy  \n",
       "count        12.000000        12.000000  \n",
       "mean          0.739759         0.443060  \n",
       "std           0.035486         0.061197  \n",
       "min           0.724240         0.248733  \n",
       "25%           0.724240         0.460726  \n",
       "50%           0.724240         0.460726  \n",
       "75%           0.725296         0.460726  \n",
       "max           0.818412         0.460726  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_batch64_MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There is a clear difference in terms of batch size that shows batch size 64 is better than 16 for MLP task, but as the number of epochs is limited and models are underfit, we only can say that batch size 64 learns faster than batch size 16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Hidden Layers</th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Age Accuracy</th>\n",
       "      <th>Gender Accuracy</th>\n",
       "      <th>Accent Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.500000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>0.301094</td>\n",
       "      <td>0.853594</td>\n",
       "      <td>0.463229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.534522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>0.029411</td>\n",
       "      <td>0.039544</td>\n",
       "      <td>0.008069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.257500</td>\n",
       "      <td>0.794583</td>\n",
       "      <td>0.455417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.282813</td>\n",
       "      <td>0.828229</td>\n",
       "      <td>0.457292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.500000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>0.294166</td>\n",
       "      <td>0.856250</td>\n",
       "      <td>0.459167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.325416</td>\n",
       "      <td>0.880625</td>\n",
       "      <td>0.470313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.345000</td>\n",
       "      <td>0.903750</td>\n",
       "      <td>0.475000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Number of Hidden Layers  Batch Size  Learning Rate  Age Accuracy  \\\n",
       "count                 8.000000         8.0       8.000000      8.000000   \n",
       "mean                  1.500000        16.0       0.000550      0.301094   \n",
       "std                   0.534522         0.0       0.000481      0.029411   \n",
       "min                   1.000000        16.0       0.000100      0.257500   \n",
       "25%                   1.000000        16.0       0.000100      0.282813   \n",
       "50%                   1.500000        16.0       0.000550      0.294166   \n",
       "75%                   2.000000        16.0       0.001000      0.325416   \n",
       "max                   2.000000        16.0       0.001000      0.345000   \n",
       "\n",
       "       Gender Accuracy  Accent Accuracy  \n",
       "count         8.000000         8.000000  \n",
       "mean          0.853594         0.463229  \n",
       "std           0.039544         0.008069  \n",
       "min           0.794583         0.455417  \n",
       "25%           0.828229         0.457292  \n",
       "50%           0.856250         0.459167  \n",
       "75%           0.880625         0.470313  \n",
       "max           0.903750         0.475000  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_batch16_CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Hidden Layers</th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Age Accuracy</th>\n",
       "      <th>Gender Accuracy</th>\n",
       "      <th>Accent Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.500000</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>0.279965</td>\n",
       "      <td>0.811780</td>\n",
       "      <td>0.465255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.534522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>0.082420</td>\n",
       "      <td>0.092930</td>\n",
       "      <td>0.027970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.164474</td>\n",
       "      <td>0.706826</td>\n",
       "      <td>0.435444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.232011</td>\n",
       "      <td>0.734580</td>\n",
       "      <td>0.447677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.500000</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>0.285362</td>\n",
       "      <td>0.807154</td>\n",
       "      <td>0.450041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.357833</td>\n",
       "      <td>0.899671</td>\n",
       "      <td>0.490748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.365543</td>\n",
       "      <td>0.917352</td>\n",
       "      <td>0.507812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Number of Hidden Layers  Batch Size  Learning Rate  Age Accuracy  \\\n",
       "count                 8.000000         8.0       8.000000      8.000000   \n",
       "mean                  1.500000        64.0       0.000550      0.279965   \n",
       "std                   0.534522         0.0       0.000481      0.082420   \n",
       "min                   1.000000        64.0       0.000100      0.164474   \n",
       "25%                   1.000000        64.0       0.000100      0.232011   \n",
       "50%                   1.500000        64.0       0.000550      0.285362   \n",
       "75%                   2.000000        64.0       0.001000      0.357833   \n",
       "max                   2.000000        64.0       0.001000      0.365543   \n",
       "\n",
       "       Gender Accuracy  Accent Accuracy  \n",
       "count         8.000000         8.000000  \n",
       "mean          0.811780         0.465255  \n",
       "std           0.092930         0.027970  \n",
       "min           0.706826         0.435444  \n",
       "25%           0.734580         0.447677  \n",
       "50%           0.807154         0.450041  \n",
       "75%           0.899671         0.490748  \n",
       "max           0.917352         0.507812  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_batch64_CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In CNN the effect of the difference of batch size is reduced but still batch size 64 learns faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analyzing Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_relu_MLP = results_df[(results_df['Activation Function'] == 'relu') & (results_df['Model'] == 'MLP')].describe()\n",
    "analyze_relu_CNN = results_df[(results_df['Activation Function'] == 'relu') & (results_df['Model'] == 'CNN')].describe()\n",
    "analyze_sigmoid_MLP = results_df[(results_df['Activation Function'] == 'sigmoid') & (results_df['Model'] == 'MLP')].describe()\n",
    "analyze_sigmoid_CNN = results_df[(results_df['Activation Function'] == 'sigmoid') & (results_df['Model'] == 'CNN')].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Hidden Layers</th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Age Accuracy</th>\n",
       "      <th>Gender Accuracy</th>\n",
       "      <th>Accent Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.190449</td>\n",
       "      <td>0.729409</td>\n",
       "      <td>0.436864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.852803</td>\n",
       "      <td>25.067182</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.032217</td>\n",
       "      <td>0.033798</td>\n",
       "      <td>0.059566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.705833</td>\n",
       "      <td>0.248733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.705833</td>\n",
       "      <td>0.448333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.171242</td>\n",
       "      <td>0.724240</td>\n",
       "      <td>0.448333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.225793</td>\n",
       "      <td>0.724979</td>\n",
       "      <td>0.460726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.244510</td>\n",
       "      <td>0.812922</td>\n",
       "      <td>0.460726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Number of Hidden Layers  Batch Size  Learning Rate  Age Accuracy  \\\n",
       "count                12.000000   12.000000      12.000000     12.000000   \n",
       "mean                  1.000000   40.000000       0.000055      0.190449   \n",
       "std                   0.852803   25.067182       0.000047      0.032217   \n",
       "min                   0.000000   16.000000       0.000010      0.166667   \n",
       "25%                   0.000000   16.000000       0.000010      0.166667   \n",
       "50%                   1.000000   40.000000       0.000055      0.171242   \n",
       "75%                   2.000000   64.000000       0.000100      0.225793   \n",
       "max                   2.000000   64.000000       0.000100      0.244510   \n",
       "\n",
       "       Gender Accuracy  Accent Accuracy  \n",
       "count        12.000000        12.000000  \n",
       "mean          0.729409         0.436864  \n",
       "std           0.033798         0.059566  \n",
       "min           0.705833         0.248733  \n",
       "25%           0.705833         0.448333  \n",
       "50%           0.724240         0.448333  \n",
       "75%           0.724979         0.460726  \n",
       "max           0.812922         0.460726  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_relu_MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Hidden Layers</th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Age Accuracy</th>\n",
       "      <th>Gender Accuracy</th>\n",
       "      <th>Accent Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.191750</td>\n",
       "      <td>0.729829</td>\n",
       "      <td>0.454530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.852803</td>\n",
       "      <td>25.067182</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.034668</td>\n",
       "      <td>0.035525</td>\n",
       "      <td>0.006472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.163333</td>\n",
       "      <td>0.705833</td>\n",
       "      <td>0.448333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.705833</td>\n",
       "      <td>0.448333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.171030</td>\n",
       "      <td>0.724240</td>\n",
       "      <td>0.454530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.232187</td>\n",
       "      <td>0.724345</td>\n",
       "      <td>0.460726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.244088</td>\n",
       "      <td>0.818412</td>\n",
       "      <td>0.460726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Number of Hidden Layers  Batch Size  Learning Rate  Age Accuracy  \\\n",
       "count                12.000000   12.000000      12.000000     12.000000   \n",
       "mean                  1.000000   40.000000       0.000055      0.191750   \n",
       "std                   0.852803   25.067182       0.000047      0.034668   \n",
       "min                   0.000000   16.000000       0.000010      0.163333   \n",
       "25%                   0.000000   16.000000       0.000010      0.166667   \n",
       "50%                   1.000000   40.000000       0.000055      0.171030   \n",
       "75%                   2.000000   64.000000       0.000100      0.232187   \n",
       "max                   2.000000   64.000000       0.000100      0.244088   \n",
       "\n",
       "       Gender Accuracy  Accent Accuracy  \n",
       "count        12.000000        12.000000  \n",
       "mean          0.729829         0.454530  \n",
       "std           0.035525         0.006472  \n",
       "min           0.705833         0.448333  \n",
       "25%           0.705833         0.448333  \n",
       "50%           0.724240         0.454530  \n",
       "75%           0.724345         0.460726  \n",
       "max           0.818412         0.460726  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_sigmoid_MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In terms of Activation Function in MLP, there is no significant difference between relu and sigmoid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Hidden Layers</th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Age Accuracy</th>\n",
       "      <th>Gender Accuracy</th>\n",
       "      <th>Accent Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.500000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>0.334017</td>\n",
       "      <td>0.887150</td>\n",
       "      <td>0.476290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.534522</td>\n",
       "      <td>25.657079</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>0.029058</td>\n",
       "      <td>0.027890</td>\n",
       "      <td>0.020313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.285362</td>\n",
       "      <td>0.834583</td>\n",
       "      <td>0.451069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.319375</td>\n",
       "      <td>0.871189</td>\n",
       "      <td>0.459167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.500000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>0.336458</td>\n",
       "      <td>0.898396</td>\n",
       "      <td>0.474375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.357833</td>\n",
       "      <td>0.904889</td>\n",
       "      <td>0.490748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.365543</td>\n",
       "      <td>0.917352</td>\n",
       "      <td>0.507812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Number of Hidden Layers  Batch Size  Learning Rate  Age Accuracy  \\\n",
       "count                 8.000000    8.000000       8.000000      8.000000   \n",
       "mean                  1.500000   40.000000       0.000550      0.334017   \n",
       "std                   0.534522   25.657079       0.000481      0.029058   \n",
       "min                   1.000000   16.000000       0.000100      0.285362   \n",
       "25%                   1.000000   16.000000       0.000100      0.319375   \n",
       "50%                   1.500000   40.000000       0.000550      0.336458   \n",
       "75%                   2.000000   64.000000       0.001000      0.357833   \n",
       "max                   2.000000   64.000000       0.001000      0.365543   \n",
       "\n",
       "       Gender Accuracy  Accent Accuracy  \n",
       "count         8.000000         8.000000  \n",
       "mean          0.887150         0.476290  \n",
       "std           0.027890         0.020313  \n",
       "min           0.834583         0.451069  \n",
       "25%           0.871189         0.459167  \n",
       "50%           0.898396         0.474375  \n",
       "75%           0.904889         0.490748  \n",
       "max           0.917352         0.507812  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_relu_CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Hidden Layers</th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Age Accuracy</th>\n",
       "      <th>Gender Accuracy</th>\n",
       "      <th>Accent Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.500000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>0.247042</td>\n",
       "      <td>0.778224</td>\n",
       "      <td>0.452194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.534522</td>\n",
       "      <td>25.657079</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>0.052403</td>\n",
       "      <td>0.060340</td>\n",
       "      <td>0.010266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.164474</td>\n",
       "      <td>0.706826</td>\n",
       "      <td>0.435444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.232011</td>\n",
       "      <td>0.734580</td>\n",
       "      <td>0.447677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.500000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>0.773320</td>\n",
       "      <td>0.452215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.820104</td>\n",
       "      <td>0.457708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.285362</td>\n",
       "      <td>0.859583</td>\n",
       "      <td>0.469167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Number of Hidden Layers  Batch Size  Learning Rate  Age Accuracy  \\\n",
       "count                 8.000000    8.000000       8.000000      8.000000   \n",
       "mean                  1.500000   40.000000       0.000550      0.247042   \n",
       "std                   0.534522   25.657079       0.000481      0.052403   \n",
       "min                   1.000000   16.000000       0.000100      0.164474   \n",
       "25%                   1.000000   16.000000       0.000100      0.232011   \n",
       "50%                   1.500000   40.000000       0.000550      0.270000   \n",
       "75%                   2.000000   64.000000       0.001000      0.283333   \n",
       "max                   2.000000   64.000000       0.001000      0.285362   \n",
       "\n",
       "       Gender Accuracy  Accent Accuracy  \n",
       "count         8.000000         8.000000  \n",
       "mean          0.778224         0.452194  \n",
       "std           0.060340         0.010266  \n",
       "min           0.706826         0.435444  \n",
       "25%           0.734580         0.447677  \n",
       "50%           0.773320         0.452215  \n",
       "75%           0.820104         0.457708  \n",
       "max           0.859583         0.469167  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_sigmoid_CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In terms of Activation Function of CNN, Relu outperformed Sigmoid activation function clearly.\n",
    "\n",
    "- The results can be changed when looking at higher nummber of layers and different learning rates.\n",
    "\n",
    "### Outcomes\n",
    "\n",
    "- Number of Hidden Layers affect the models learning speed, it can be more robust increasing the number of layers if number of epochs are increased.\n",
    "\n",
    "- Batch size also affects speed of learning, when increased it can show higher performance. \n",
    "\n",
    "- Learning Rate affects the learning of speed and if it is too small it can get into local minimum, but it also can be more robust.\n",
    "\n",
    "- When choosing activation function, we can trust on Relu instead of Sigmoid. It can give more accurate results esspecially in CNN architectures."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

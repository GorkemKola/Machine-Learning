{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1\n",
    "\n",
    "### Maximum Likelihood Estimate (MLE)\n",
    "\n",
    "- You have a coin that you think is biased, you flip it 5 times and get the sequence HTHTH. What is the maximum likelihood estimate for the probability of getting heads?\n",
    "    \n",
    "    - As result shows 3 Heads and 2 Tails, our likelyhood of getting heads should be 3 / 5\n",
    "\n",
    "- You know that candy prices are normally distributed with mean μ and standard deviation σ. You have three candy pricing 2, 3, 5 lira. What is the maximum likelihood for μ?\n",
    "\n",
    "    - As we want to estimate likelihood for μ, we need to get mean of 2, 3, 5 and that is (2+3+5) / 3 = 10 /3 ~= 3.33\n",
    "\n",
    "- Suppose that X is a discrete random variable with the following probability mass function: where 0 ≤ θ ≤ 1 is a parameter. The following 10 independent observations\n",
    "\n",
    "![Question 3 Table](imgs/q3.png)\n",
    "\n",
    "were taken from such a distribution: (3, 0, 2, 1, 3, 2, 1, 0, 2, 1). What is the maximum likelihood estimate of θ\n",
    "\n",
    "![Question 4 L(θ)](imgs/q4_1.png)\n",
    "![Question 4 Solution](imgs/q4_2.png)\n",
    "\n",
    "The solution is like up above, but the problem is there roots contains 0 and 1, and if we use them in formula we get 0 on some values, so we can conclude they are not roots so root 0.5 is MLE(θ)\n",
    "\n",
    "### Naive Bayes\n",
    "\n",
    "- The bank uses the information of its customers to give credits. The attributes used are sex, education, age , income and credit ( it can be yes or no).\n",
    "- Can a male 23-year-old university graduate working class customer get a credit?\n",
    "\n",
    "| Ex | Sex     | Education  | Age   | Income       | Credit |\n",
    "|----|---------|------------|-------|--------------|--------|\n",
    "| 1  | female  | high school| 16-25 | poverty class| no     |\n",
    "| 2  | female  | none       | 16-25 | poverty class| no     |\n",
    "| 3  | female  | high school| 26-39 | upper class  | yes    |\n",
    "| 4  | male    | high school| 40-64 | poverty class| no     |\n",
    "| 5  | male    | university | 26-39 | upper class  | yes    |\n",
    "| 6  | female  | university | 16-25 | working class| no     |\n",
    "| 7  | male    | none       | 26-39 | working class| yes    |\n",
    "| 8  | male    | university | 40-64 | upper class  | yes    |\n",
    "| 9  | female  | university | 26-39 | working class| no     |\n",
    "| 10 | female  | high school| 40-64 | upper class  | yes    |\n",
    "\n",
    "![Naive Bayes Formula](imgs/naive1.png)\n",
    "![Yes Likelihood](imgs/naive_yes.png)\n",
    "![No Likelihood](imgs/naive_no.png)\n",
    "\n",
    "We applied Laplace smoothing because there were 0s in likelihoods, we added 1 to numerator and unique class counts to denominator.\n",
    "\n",
    "As 0.69 > 0.23, we can say that the answer is no\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Importing important libraries\n",
    "\n",
    "    numpy: Array operations\n",
    "    numba.jit: faster Array operations on numpy\n",
    "    sklearn.model_selection.train_test_split: splitting into train and test\n",
    "'''\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numba import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0. Other Class/Image Border',\n",
       "       '1. Road Markings, Asphalt, Landing Pad', '2. Water',\n",
       "       '3. Building', '4. Vehicle (Car, Truck, or Bus)', '5. Person',\n",
       "       '6. Vegetation', '7. Wood Panel', '8. Rocks, Sand',\n",
       "       '9. Chair, Table'], dtype='<U38')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classes to use in visualization\n",
    "classes = np.load('data/classes.npy')\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading All datas\n",
    "data = np.load('data/train_data.npy')\n",
    "labels = np.load('data/train_labels.npy')\n",
    "mask = np.load('data/train_mask.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[mask > 0]\n",
    "labels = labels[mask > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting all datas into train and test\n",
    "train_data, test_data, train_labels, test_labels, = train_test_split(data, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rgb, train_infrared = train_data[:, :3], train_data[:, 3:]\n",
    "test_rgb, test_infrared = test_data[:, :3], test_data[:, 3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((31777172, 6), (31777172,), (31777172, 3), (31777172, 3))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Shapes\n",
    "train_data.shape, train_labels.shape, train_rgb.shape, train_infrared.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7944293, 6), (7944293,), (7944293, 3), (7944293, 3))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Shapes\n",
    "test_data.shape, test_labels.shape, test_rgb.shape, test_infrared.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_data = np.load('data/train_data.npy')\n",
    "train_labels = np.load('data/train_labels.npy')\n",
    "train_mask = np.load('data/train_mask.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def _calculate_prob(x, mean, std):\n",
    "    '''\n",
    "        Definition\n",
    "        __________\n",
    "        Calculates Probability for a feature\n",
    "\n",
    "        Formula\n",
    "        __________\n",
    "        exponent = e**(-((X - mean) ** 2 / ( 2 * STD ** 2)))\n",
    "        1 / (SQRT(2 * PI) * STD) * exponent\n",
    "\n",
    "        # it gets likelyhood from Gaussian Distribution\n",
    "    '''\n",
    "    exponent = np.exp(-((x - mean) ** 2) / (2 * std ** 2))\n",
    "    return (1 / (np.sqrt(2 * np.pi) * std)) * exponent\n",
    "\n",
    "@jit(nopython=True)\n",
    "def calculate_probabilities(X, priors, parameters):\n",
    "    '''\n",
    "        This method returns likelyhoods of each class\n",
    "    '''\n",
    "    probabilities = np.zeros((X.shape[0], len(priors)))\n",
    "    \n",
    "    for i in range(len(priors)):\n",
    "        prior = priors[i]\n",
    "        params = parameters[i]\n",
    "        prob = prior + np.sum(np.log(_calculate_prob(X, params[:, 0], params[:, 1])), axis=1)\n",
    "        probabilities[:, i] = prob\n",
    "    \n",
    "    return probabilities\n",
    "def fit(X, y):\n",
    "    '''\n",
    "        Definition\n",
    "        ___________\n",
    "        Fit function to get parameters and priors\n",
    "\n",
    "        Parameters\n",
    "        ___________\n",
    "        X: np.array\n",
    "            train data\n",
    "\n",
    "        y: np.array\n",
    "            train labels\n",
    "\n",
    "    '''\n",
    "    labels = np.unique(y)\n",
    "    channels = X.shape[-1]\n",
    "    priors = []\n",
    "    parameters = np.zeros((len(labels), channels, 2))\n",
    "    \n",
    "    for i, c in enumerate(labels):\n",
    "        X_c = X[y == c]\n",
    "        prior = np.log(X_c.shape[0] / X.reshape(-1, channels).shape[0])\n",
    "        priors.append(prior)\n",
    "        \n",
    "        for j, feature in enumerate(X_c.T):\n",
    "            mean = np.mean(feature)\n",
    "            std = np.std(feature)\n",
    "            parameters[i, j] = mean, std\n",
    "    \n",
    "    return priors, parameters, channels\n",
    "@jit(nopython=True)\n",
    "def predict(X, priors, parameters):\n",
    "    '''\n",
    "        Definition\n",
    "        ___________\n",
    "        This function predict labels according to given test value\n",
    "\n",
    "        Parameters\n",
    "        ___________\n",
    "        X : np.array\n",
    "            Given Matrix to segment\n",
    "\n",
    "        priors : List[int]\n",
    "            prior knowledges\n",
    "\n",
    "        parameters : np.array\n",
    "            Mean and Standard deviation parameters for each label and features\n",
    "\n",
    "        Returns\n",
    "        ________\n",
    "        Class probabilities\n",
    "    '''\n",
    "    return calculate_probabilities(X, priors, parameters)\n",
    "\n",
    "def GNB(X_train, y_train, X_test):\n",
    "    '''\n",
    "        Definition\n",
    "        ___________\n",
    "        This function runs Gaussian Naive Bayes on given train and test data\n",
    "\n",
    "        Parameters\n",
    "        ___________\n",
    "        X_train : np.array\n",
    "            Training data\n",
    "\n",
    "        y_train : np.array\n",
    "            Training labels\n",
    "\n",
    "        X_test : np.array\n",
    "            Test data\n",
    "\n",
    "        Returns\n",
    "        ________\n",
    "        predictions : np.array\n",
    "            Predicted labels for test data\n",
    "    '''\n",
    "    priors, parameters, channels = fit(X_train, y_train)\n",
    "    predictions = predict(X_test.reshape(-1, channels), priors, parameters)\n",
    "    return predictions.reshape((*X_test.shape[:-1], predictions.shape[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Applied to each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_85902/3267550726.py:85: NumbaPendingDeprecationWarning: \n",
      "Encountered the use of a type that is scheduled for deprecation: type 'reflected list' found for argument 'priors' of function 'calculate_probabilities'.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-reflection-for-list-and-set-types\n",
      "\n",
      "File \"../../../../../../tmp/ipykernel_85902/3267550726.py\", line 18:\n",
      "<source missing, REPL/exec in use?>\n",
      "\n",
      "  return calculate_probabilities(X, priors, parameters)\n",
      "/home/grkmkola/miniconda3/envs/ml/lib/python3.11/site-packages/numba/core/ir_utils.py:2172: NumbaPendingDeprecationWarning: \n",
      "Encountered the use of a type that is scheduled for deprecation: type 'reflected list' found for argument 'priors' of function 'predict'.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-reflection-for-list-and-set-types\n",
      "\n",
      "File \"../../../../../../tmp/ipykernel_85902/3267550726.py\", line 63:\n",
      "<source missing, REPL/exec in use?>\n",
      "\n",
      "  warnings.warn(NumbaPendingDeprecationWarning(msg, loc=loc))\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "for i in range(train_data.shape[-1]):\n",
    "    train_X = np.expand_dims(train_data[:, i], axis=-1)\n",
    "    test_X = np.expand_dims(test_data[:, i], axis=-1)\n",
    "    pred = GNB(train_X, train_labels, test_X)\n",
    "    predictions.append(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes applied to RGB channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rgb = GNB(train_rgb, train_labels, test_rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes applied to Infrared channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_infra = GNB(train_infrared, train_labels, test_infrared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes applied to All channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_85902/3267550726.py:85: NumbaPendingDeprecationWarning: \n",
      "Encountered the use of a type that is scheduled for deprecation: type 'reflected list' found for argument 'priors' of function 'calculate_probabilities'.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-reflection-for-list-and-set-types\n",
      "\n",
      "File \"../../../../../../tmp/ipykernel_85902/3267550726.py\", line 18:\n",
      "<source missing, REPL/exec in use?>\n",
      "\n",
      "  return calculate_probabilities(X, priors, parameters)\n",
      "/home/grkmkola/miniconda3/envs/ml/lib/python3.11/site-packages/numba/core/ir_utils.py:2172: NumbaPendingDeprecationWarning: \n",
      "Encountered the use of a type that is scheduled for deprecation: type 'reflected list' found for argument 'priors' of function 'predict'.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-reflection-for-list-and-set-types\n",
      "\n",
      "File \"../../../../../../tmp/ipykernel_85902/3267550726.py\", line 63:\n",
      "<source missing, REPL/exec in use?>\n",
      "\n",
      "  warnings.warn(NumbaPendingDeprecationWarning(msg, loc=loc))\n"
     ]
    }
   ],
   "source": [
    "pred_all = GNB(train_data, train_labels, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(true, pred, n_class):\n",
    "\n",
    "    cm = np.zeros((n_class, n_class))\n",
    "    for i in range(n_class):\n",
    "        for j in range(n_class):\n",
    "            cm[i, j] = np.sum((true == i) & (pred == j))\n",
    "    return cm\n",
    "\n",
    "def accuracy(true, pred):\n",
    "    cm = confusion_matrix(true, pred, 10)\n",
    "    tp_tn = np.diag(cm)\n",
    "    return np.sum(tp_tn) / np.sum(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracies(*preds, labels):\n",
    "    for pred in preds:\n",
    "        yield accuracy(np.argmax(pred, axis=1), labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    'Accuracy of channel Red Channel',\n",
    "    'Accuracy of channel Green Channel',\n",
    "    'Accuracy of channel Blue Channel',\n",
    "    'Accuracy of channel Infrared 1 Channel',\n",
    "    'Accuracy of channel Infrared 2 Channel',\n",
    "    'Accuracy of channel Infrared 3 Channel',\n",
    "    'Accuracy of channel RGB Channels',\n",
    "    'Accuracy of channel Infrared Channels',\n",
    "    'Accuracy of all channels'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Accuracy of channel Red Channel', 0.6514063617744209),\n",
       " ('Accuracy of channel Green Channel', 0.5721563894987257),\n",
       " ('Accuracy of channel Blue Channel', 0.6208265480641261),\n",
       " ('Accuracy of channel Infrared 1 Channel', 0.6025042127726156),\n",
       " ('Accuracy of channel Infrared 2 Channel', 0.7235960456141283),\n",
       " ('Accuracy of channel Infrared 3 Channel', 0.743812444984091),\n",
       " ('Accuracy of channel RGB Channels', 0.5166646043895914),\n",
       " ('Accuracy of channel Infrared Channels', 0.6494166315366263),\n",
       " ('Accuracy of all channels', 0.8625705270437533)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies = calculate_accuracies(*predictions, pred_rgb, pred_infra, pred_all, labels=test_labels)\n",
    "list(zip(texts, accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The RGB channels and Infrared channels are getting worse results than they seperately get. The reason why probably they are highly correlated and extract similar features (mean, std). This made this models worse.\n",
    "- This Results indicates that, infrared channels is better than RGB channels, both together and seperately. But even though they are better than RGB channels when they get together they achieve more robust results. The reason why should be, RGB channels and Infrared channels are not correlated with each other and it would get better results as they extract different features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
